"""
æ–‡æœ¬ä¼˜åŒ–æœåŠ¡ - é›†æˆçœŸå®LLM API
"""

import asyncio
import aiohttp
import json
import time
from typing import Dict, List, Optional, Any
from datetime import datetime
import re


class TextOptimizeService:
    """æ–‡æœ¬ä¼˜åŒ–æœåŠ¡ç±» - é›†æˆå¤šç§LLM API"""

    def __init__(self, config: Dict = None):
        """åˆå§‹åŒ–æ–‡æœ¬ä¼˜åŒ–æœåŠ¡"""
        self.config = config or {}
        self.api_keys = self.config.get("llm_apis", {})

        # æ”¯æŒçš„LLMæä¾›å•†é…ç½®
        self.providers = {
            "openai": {
                "name": "OpenAI GPT-4",
                "available": bool(self.api_keys.get("openai")),
                "base_url": "https://api.openai.com/v1",
                "model": "gpt-4-turbo-preview",
                "max_tokens": 4000,
                "temperature": 0.7
            },
            "zhipu": {
                "name": "æ™ºè°±GLM-4",
                "available": bool(self.api_keys.get("zhipu")),
                "base_url": "https://open.bigmodel.cn/api/paas/v4",
                "model": "glm-4",
                "max_tokens": 4000,
                "temperature": 0.7
            },
            "moonshot": {
                "name": "Moonshot Kimi",
                "available": bool(self.api_keys.get("moonshot")),
                "base_url": "https://api.moonshot.cn/v1",
                "model": "moonshot-v1-8k",
                "max_tokens": 4000,
                "temperature": 0.7
            },
            "doubao": {
                "name": "å­—èŠ‚è±†åŒ…",
                "available": bool(self.api_keys.get("doubao")),
                "base_url": "https://ark.cn-beijing.volces.com/api/v3",
                "model": "doubao-pro-32k",
                "max_tokens": 4000,
                "temperature": 0.7
            },
            "qwen": {
                "name": "é€šä¹‰åƒé—®",
                "available": bool(self.api_keys.get("qwen")),
                "base_url": "https://dashscope.aliyuncs.com/api/v1",
                "model": "qwen-turbo",
                "max_tokens": 4000,
                "temperature": 0.7
            }
        }

        # æ–‡æœ¬ä¼˜åŒ–æ¨¡å¼
        self.optimization_modes = {
            "creative": {
                "name": "åˆ›æ„ä¼˜åŒ–",
                "description": "å¢å¼ºåˆ›æ„å’Œè¡¨ç°åŠ›ï¼Œé€‚åˆå†…å®¹åˆ›ä½œ",
                "prompt_template": """è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œåˆ›æ„ä¼˜åŒ–ï¼Œä½¿å…¶æ›´åŠ ç”ŸåŠ¨æœ‰è¶£ï¼Œé€‚åˆå†…å®¹åˆ›ä½œï¼š

åŸæ–‡ï¼š{original_text}

è¦æ±‚ï¼š
1. ä¿æŒåŸæ„ä¸å˜ï¼Œä½†å¢å¼ºè¡¨ç°åŠ›
2. ä½¿ç”¨æ›´ç”ŸåŠ¨çš„è¯æ±‡å’Œè¡¨è¾¾æ–¹å¼
3. é€‚åˆç¤¾äº¤åª’ä½“å‘å¸ƒ
4. æ§åˆ¶åœ¨ç›¸è¿‘çš„å­—æ•°èŒƒå›´å†…
5. ä¿æŒè¯­è¨€æµç•…è‡ªç„¶

ä¼˜åŒ–åçš„æ–‡æœ¬ï¼š"""
            },
            "professional": {
                "name": "ä¸“ä¸šä¼˜åŒ–",
                "description": "æå‡ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼Œé€‚åˆæ­£å¼åœºåˆ",
                "prompt_template": """è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œä¸“ä¸šä¼˜åŒ–ï¼Œä½¿å…¶æ›´åŠ å‡†ç¡®å’Œä¸“ä¸šï¼š

åŸæ–‡ï¼š{original_text}

è¦æ±‚ï¼š
1. ä½¿ç”¨æ›´ä¸“ä¸šçš„æœ¯è¯­å’Œè¡¨è¾¾
2. ç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œæƒå¨æ€§
3. é€»è¾‘æ¸…æ™°ï¼Œæ¡ç†åˆ†æ˜
4. é€‚åˆä¸“ä¸šé¢†åŸŸäº¤æµ
5. ä¿æŒå®¢è§‚ä¸­æ€§çš„è¯­è°ƒ

ä¼˜åŒ–åçš„æ–‡æœ¬ï¼š"""
            },
            "concise": {
                "name": "ç®€æ´ä¼˜åŒ–",
                "description": "ç²¾ç®€å†…å®¹ï¼Œçªå‡ºé‡ç‚¹ï¼Œæé«˜å¯è¯»æ€§",
                "prompt_template": """è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œç®€æ´ä¼˜åŒ–ï¼Œä½¿å…¶æ›´åŠ ç²¾ç‚¼å’Œæ˜“è¯»ï¼š

åŸæ–‡ï¼š{original_text}

è¦æ±‚ï¼š
1. åˆ é™¤å†—ä½™ä¿¡æ¯ï¼Œä¿ç•™æ ¸å¿ƒå†…å®¹
2. ä½¿ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€
3. çªå‡ºé‡ç‚¹ï¼Œæ¡ç†æ¸…æ™°
4. æé«˜å¯è¯»æ€§å’Œç†è§£åº¦
5. æ§åˆ¶å­—æ•°åœ¨åŸæ–‡çš„70%ä»¥å†…

ä¼˜åŒ–åçš„æ–‡æœ¬ï¼š"""
            },
            "seo": {
                "name": "SEOä¼˜åŒ–",
                "description": "ä¼˜åŒ–æœç´¢å¼•æ“æ’åï¼Œå¢åŠ å…³é”®è¯å¯†åº¦",
                "prompt_template": """è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡ŒSEOä¼˜åŒ–ï¼Œæå‡æœç´¢å¼•æ“æ’åï¼š

åŸæ–‡ï¼š{original_text}

è¦æ±‚ï¼š
1. åˆç†æ·»åŠ ç›¸å…³å…³é”®è¯
2. ä¼˜åŒ–æ ‡é¢˜å’Œæè¿°
3. æé«˜å†…å®¹çš„å¯è¯»æ€§å’Œä»·å€¼
4. ä¿æŒè‡ªç„¶æµç•…ï¼Œé¿å…å…³é”®è¯å †ç Œ
5. é€‚åˆæœç´¢å¼•æ“æ”¶å½•

ä¼˜åŒ–åçš„æ–‡æœ¬ï¼š"""
            },
            "social": {
                "name": "ç¤¾äº¤ä¼˜åŒ–",
                "description": "ä¼˜åŒ–ç¤¾äº¤åª’ä½“è¡¨è¾¾ï¼Œå¢åŠ äº’åŠ¨æ€§",
                "prompt_template": """è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œç¤¾äº¤åª’ä½“ä¼˜åŒ–ï¼Œå¢åŠ äº’åŠ¨æ€§å’Œä¼ æ’­åŠ›ï¼š

åŸæ–‡ï¼š{original_text}

è¦æ±‚ï¼š
1. ä½¿ç”¨æ›´è´´è¿‘ç¤¾äº¤åª’ä½“çš„è¡¨è¾¾æ–¹å¼
2. å¢åŠ äº’åŠ¨å…ƒç´ å’Œè¯é¢˜æ ‡ç­¾
3. æé«˜å†…å®¹çš„å¸å¼•åŠ›å’Œåˆ†äº«ä»·å€¼
4. é€‚åˆåœ¨å¾®åšã€æŠ–éŸ³ç­‰å¹³å°å‘å¸ƒ
5. è¯­è¨€æ´»æ³¼æœ‰è¶£ï¼Œè´´è¿‘ç”¨æˆ·

ä¼˜åŒ–åçš„æ–‡æœ¬ï¼š"""
            }
        }

        print("ğŸ¤– æ–‡æœ¬ä¼˜åŒ–æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print(f"   å¯ç”¨LLM: {[p['name'] for p in self.providers.values() if p['available']]}")

    async def optimize_text(self, text: str, provider: str = "zhipu", mode: str = "creative",
                          custom_prompt: str = None) -> Dict[str, Any]:
        """ä¼˜åŒ–æ–‡æœ¬"""
        print(f"ğŸ¯ å¼€å§‹æ–‡æœ¬ä¼˜åŒ–:")
        print(f"   æä¾›å•†: {provider}")
        print(f"   ä¼˜åŒ–æ¨¡å¼: {mode}")
        print(f"   åŸæ–‡é•¿åº¦: {len(text)}å­—")
        print(f"   åŸæ–‡å†…å®¹: {text[:50]}...")

        # éªŒè¯å‚æ•°
        if not text.strip():
            return self._create_error_response("æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")

        if provider not in self.providers:
            return self._create_error_response(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")

        if not self.providers[provider]["available"]:
            return self._create_error_response(f"LLMæä¾›å•† {provider} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")

        if mode not in self.optimization_modes and custom_prompt is None:
            return self._create_error_response(f"ä¸æ”¯æŒçš„ä¼˜åŒ–æ¨¡å¼: {mode}")

        try:
            # æ„å»ºæç¤ºè¯
            if custom_prompt:
                prompt = custom_prompt.replace("{original_text}", text)
            else:
                mode_config = self.optimization_modes[mode]
                prompt = mode_config["prompt_template"].replace("{original_text}", text)

            # è°ƒç”¨LLM API
            start_time = time.time()
            optimized_text = await self._call_llm_api(provider, prompt)
            generation_time = time.time() - start_time

            if optimized_text:
                print(f"âœ… æ–‡æœ¬ä¼˜åŒ–å®Œæˆ:")
                print(f"   ä¼˜åŒ–åé•¿åº¦: {len(optimized_text)}å­—")
                print(f"   è€—æ—¶: {generation_time:.2f}ç§’")
                print(f"   ä¼˜åŒ–åå†…å®¹: {optimized_text[:50]}...")

                return {
                    "original_text": text,
                    "optimized_text": optimized_text,
                    "provider": provider,
                    "provider_name": self.providers[provider]["name"],
                    "mode": mode,
                    "mode_name": self.optimization_modes.get(mode, {}).get("name", mode),
                    "generation_time": generation_time,
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    "text_length": {
                        "original": len(text),
                        "optimized": len(optimized_text),
                        "ratio": len(optimized_text) / len(text) if text else 0
                    }
                }
            else:
                return self._create_error_response("LLM APIè°ƒç”¨å¤±è´¥")

        except Exception as e:
            print(f"âŒ æ–‡æœ¬ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return self._create_error_response(f"ä¼˜åŒ–å¤±è´¥: {str(e)}")

    async def _call_llm_api(self, provider: str, prompt: str) -> Optional[str]:
        """è°ƒç”¨LLM API"""
        provider_config = self.providers[provider]
        api_key = self.api_keys.get(provider)

        if not api_key:
            print(f"âŒ ç¼ºå°‘ {provider} çš„APIå¯†é’¥")
            return None

        try:
            if provider == "openai":
                return await self._call_openai_api(prompt, provider_config, api_key)
            elif provider == "zhipu":
                return await self._call_zhipu_api(prompt, provider_config, api_key)
            elif provider == "moonshot":
                return await self._call_moonshot_api(prompt, provider_config, api_key)
            elif provider == "doubao":
                return await self._call_doubao_api(prompt, provider_config, api_key)
            elif provider == "qwen":
                return await self._call_qwen_api(prompt, provider_config, api_key)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
                return None

        except Exception as e:
            print(f"âŒ LLM APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None

    async def _call_openai_api(self, prompt: str, config: Dict, api_key: str) -> Optional[str]:
        """è°ƒç”¨OpenAI API"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": config["model"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿æå‡æ–‡æœ¬è´¨é‡å’Œè¡¨ç°åŠ›ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": config["max_tokens"],
            "temperature": config["temperature"]
        }

        return await self._make_http_request(config["base_url"] + "/chat/completions", headers, data)

    async def _call_zhipu_api(self, prompt: str, config: Dict, api_key: str) -> Optional[str]:
        """è°ƒç”¨æ™ºè°±AI API"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": config["model"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿æå‡æ–‡æœ¬è´¨é‡å’Œè¡¨ç°åŠ›ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": config["max_tokens"],
            "temperature": config["temperature"]
        }

        return await self._make_http_request(config["base_url"] + "/chat/completions", headers, data)

    async def _call_moonshot_api(self, prompt: str, config: Dict, api_key: str) -> Optional[str]:
        """è°ƒç”¨Moonshot API"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": config["model"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿æå‡æ–‡æœ¬è´¨é‡å’Œè¡¨ç°åŠ›ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": config["max_tokens"],
            "temperature": config["temperature"]
        }

        return await self._make_http_request(config["base_url"] + "/chat/completions", headers, data)

    async def _call_doubao_api(self, prompt: str, config: Dict, api_key: str) -> Optional[str]:
        """è°ƒç”¨è±†åŒ…API"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": config["model"],
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿æå‡æ–‡æœ¬è´¨é‡å’Œè¡¨ç°åŠ›ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": config["max_tokens"],
            "temperature": config["temperature"]
        }

        return await self._make_http_request(config["base_url"] + "/chat/completions", headers, data)

    async def _call_qwen_api(self, prompt: str, config: Dict, api_key: str) -> Optional[str]:
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": config["model"],
            "input": {
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿æå‡æ–‡æœ¬è´¨é‡å’Œè¡¨ç°åŠ›ã€‚"},
                    {"role": "user", "content": prompt}
                ]
            },
            "parameters": {
                "max_tokens": config["max_tokens"],
                "temperature": config["temperature"]
            }
        }

        return await self._make_http_request(config["base_url"] + "/services/aigc/text-generation/generation", headers, data)

    async def _make_http_request(self, url: str, headers: Dict, data: Dict, timeout: int = 30) -> Optional[str]:
        """å‘é€HTTPè¯·æ±‚"""
        try:
            timeout_obj = aiohttp.ClientTimeout(total=timeout)
            async with aiohttp.ClientSession(timeout=timeout_obj) as session:
                async with session.post(url, headers=headers, json=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        return self._extract_text_from_response(result)
                    else:
                        error_text = await response.text()
                        print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                        return None

        except asyncio.TimeoutError:
            print(f"âŒ APIè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            print(f"âŒ APIè¯·æ±‚å¼‚å¸¸: {str(e)}")
            return None

    def _extract_text_from_response(self, response: Dict) -> Optional[str]:
        """ä»APIå“åº”ä¸­æå–æ–‡æœ¬"""
        try:
            # OpenAIæ ¼å¼
            if "choices" in response:
                return response["choices"][0]["message"]["content"]
            # é€šä¹‰åƒé—®æ ¼å¼
            elif "output" in response and "text" in response["output"]:
                return response["output"]["text"]
            # å…¶ä»–æ ¼å¼
            elif "text" in response:
                return response["text"]
            elif "content" in response:
                return response["content"]
            else:
                print(f"âŒ æ— æ³•è§£æAPIå“åº”æ ¼å¼: {response}")
                return None

        except Exception as e:
            print(f"âŒ æå–å“åº”æ–‡æœ¬å¤±è´¥: {str(e)}")
            return None

    def _create_error_response(self, error_msg: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return {
            "error": error_msg,
            "original_text": "",
            "optimized_text": "",
            "provider": "",
            "mode": "",
            "generation_time": 0,
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

    async def batch_optimize(self, texts: List[str], **kwargs) -> List[Dict[str, Any]]:
        """æ‰¹é‡ä¼˜åŒ–æ–‡æœ¬"""
        results = []

        for i, text in enumerate(texts):
            print(f"ğŸ”„ æ‰¹é‡ä¼˜åŒ–è¿›åº¦: {i+1}/{len(texts)}")

            try:
                result = await self.optimize_text(text, **kwargs)
                results.append({
                    "index": i + 1,
                    "status": "success" if not result.get("error") else "error",
                    "data": result
                })
            except Exception as e:
                results.append({
                    "index": i + 1,
                    "status": "error",
                    "error": str(e)
                })

        return results

    def get_available_providers(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨çš„LLMæä¾›å•†"""
        return [
            {
                "id": provider_id,
                "name": config["name"],
                "available": config["available"],
                "model": config["model"]
            }
            for provider_id, config in self.providers.items()
        ]

    def get_optimization_modes(self) -> List[Dict[str, Any]]:
        """è·å–ä¼˜åŒ–æ¨¡å¼"""
        return [
            {
                "id": mode_id,
                "name": config["name"],
                "description": config["description"]
            }
            for mode_id, config in self.optimization_modes.items()
        ]

    async def test_provider(self, provider: str) -> Dict[str, Any]:
        """æµ‹è¯•LLMæä¾›å•†è¿æ¥"""
        if provider not in self.providers:
            return {
                "success": False,
                "message": f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}"
            }

        if not self.providers[provider]["available"]:
            return {
                "success": False,
                "message": f"æä¾›å•† {provider} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥"
            }

        try:
            test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚"
            result = await self.optimize_text(test_text, provider=provider, mode="creative")

            if result and not result.get("error"):
                return {
                    "success": True,
                    "message": f"{provider} è¿æ¥æµ‹è¯•æˆåŠŸ",
                    "provider": provider,
                    "provider_name": self.providers[provider]["name"],
                    "test_result": result
                }
            else:
                return {
                    "success": False,
                    "message": f"{provider} è¿æ¥æµ‹è¯•å¤±è´¥",
                    "error": result.get("error", "æœªçŸ¥é”™è¯¯")
                }

        except Exception as e:
            return {
                "success": False,
                "message": f"{provider} è¿æ¥æµ‹è¯•å¼‚å¸¸",
                "error": str(e)
            }


def get_text_optimize_service(config: Dict = None) -> TextOptimizeService:
    """è·å–æ–‡æœ¬ä¼˜åŒ–æœåŠ¡å®ä¾‹"""
    return TextOptimizeService(config)