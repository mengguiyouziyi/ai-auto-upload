#!/usr/bin/env python3
"""
å®Œæ•´çš„AIåª’ä½“å¹³å°åç«¯æœåŠ¡
"""

from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
import sys
import os
import httpx
import json
import uuid
import asyncio
import random
import time
import aiohttp
from datetime import datetime
from typing import Optional, Dict, Any, List
from services.auth_service import batch_check_cookies
try:
    # ä½¿ç”¨ç®€åŒ–ç‰ˆç™»å½•æœåŠ¡è§£å†³QRç ç™»å½•é—®é¢˜
    from services.login_service_simple import run_login_process, login_service
    print("âœ… ç®€åŒ–ç‰ˆç™»å½•æœåŠ¡å¯¼å…¥æˆåŠŸ - è§£å†³QRç è¿æ¥å¤±è´¥é—®é¢˜")
except ImportError:
    # å›é€€åˆ°åŸç‰ˆç™»å½•æœåŠ¡
    from services.login_service import run_login_process, login_service
    print("âœ… åŸç‰ˆç™»å½•æœåŠ¡å¯¼å…¥æˆåŠŸ")
from bs4 import BeautifulSoup
from pathlib import Path
import re

# æ·»åŠ social-auto-uploadè·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent
SOCIAL_ROOT = PROJECT_ROOT / ".." / "social-auto-upload"

if str(SOCIAL_ROOT) not in sys.path:
    sys.path.insert(0, str(SOCIAL_ROOT))

try:
    # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬è§£å†³ä¸Šä¼ é—®é¢˜
    from routes.douyin_upload_simple import DouYinVideo
    from conf import BASE_DIR
    from utils.files_times import generate_schedule_time_next_day
    SOCIAL_AUTO_UPLOAD_AVAILABLE = True
    print("âœ… ç®€åŒ–ç‰ˆæŠ–éŸ³å‘å¸ƒæ¨¡å—å¯¼å…¥æˆåŠŸ - è§£å†³tabindex=-1é—®é¢˜")
except ImportError:
    try:
        # å›é€€åˆ°GitHubä¼˜åŒ–ç‰ˆæœ¬
        from routes.douyin_upload_github import DouYinVideo
        from conf import BASE_DIR
        from utils.files_times import generate_schedule_time_next_day
        SOCIAL_AUTO_UPLOAD_AVAILABLE = True
        print("âœ… GitHubä¼˜åŒ–ç‰ˆæŠ–éŸ³å‘å¸ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError:
        try:
            # æœ€åå›é€€åˆ°åŸç‰ˆ
            from conf import BASE_DIR
            from uploader.douyin_uploader.main import DouYinVideo
            from utils.files_times import generate_schedule_time_next_day
            SOCIAL_AUTO_UPLOAD_AVAILABLE = True
            print("âœ… åŸç‰ˆæŠ–éŸ³å‘å¸ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            print(f"âš ï¸ æ— æ³•å¯¼å…¥social-auto-uploadæ¨¡å—: {e}")
            SOCIAL_AUTO_UPLOAD_AVAILABLE = False
            BASE_DIR = PROJECT_ROOT / ".." / "social-auto-upload"

# æ•°æ®åº“è·¯å¾„
DATABASE_PATH = BASE_DIR / "db" / "database.db"
COOKIE_STORAGE = BASE_DIR / "cookiesFile"

# å‘å¸ƒä»»åŠ¡å­˜å‚¨
publish_tasks: Dict[str, Dict] = {}

# é‡å¤å‘å¸ƒæ£€æµ‹å­˜å‚¨ - é˜²æ­¢åŒä¸€è§†é¢‘é‡å¤å‘å¸ƒ
publishing_videos: Dict[str, str] = {}  # {video_path: task_id}

# ==================== LLMæœåŠ¡é…ç½® ====================
try:
    from services.llm.llm_service import get_llm_service, LLMProvider

    # é…ç½®GLM APIå¯†é’¥
    llm_config = {
        "api_keys": {
            "glm": {
                "api_key": "f7c16ac7a2d938e149a983c46323c5ce.9KB1MLzSvDg24LDb",
                "base_url": "https://open.bigmodel.cn/api/paas/v4",
                "model": "glm-4.6",
                "api_format": "openai"
            }
        }
    }

    # åˆå§‹åŒ–LLMæœåŠ¡
    llm_service = get_llm_service(llm_config)
    print("âœ… LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼ŒGLM-4.6å·²é…ç½®")

except ImportError as e:
    print(f"âš ï¸ LLMæœåŠ¡å¯¼å…¥å¤±è´¥: {e}")
    llm_service = None
except Exception as e:
    print(f"âš ï¸ LLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    llm_service = None

app = FastAPI(title="AIåª’ä½“å¹³å°", version="1.0.0")

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173", "http://localhost:5174"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆ›å»ºæœ¬åœ°è§†é¢‘å­˜å‚¨ç›®å½•
LOCAL_VIDEO_DIR = Path("./generated_videos")
LOCAL_VIDEO_DIR.mkdir(exist_ok=True)
print(f"ğŸ“ æœ¬åœ°è§†é¢‘å­˜å‚¨ç›®å½•: {LOCAL_VIDEO_DIR.absolute()}")

# ==================== è§†é¢‘ç”ŸæˆæœåŠ¡ ====================

class VideoRequest:
    def __init__(self, provider: str, prompt: str, duration: int = 8, width: int = 512, height: int = 512, fps: int = 16, seed: Optional[int] = None):
        self.provider = provider
        self.prompt = prompt
        self.duration = duration
        self.width = width
        self.height = height
        self.fps = fps
        self.seed = seed


class PublishRequest(BaseModel):
    """å‘å¸ƒè¯·æ±‚æ¨¡å‹"""
    title: str
    video_path: str
    tags: List[str] = []
    account_id: Optional[str] = None
    publish_time: Optional[str] = None  # ISOæ ¼å¼æ—¶é—´å­—ç¬¦ä¸²
    account_file: Optional[str] = None


class PublishResponse(BaseModel):
    """å‘å¸ƒå“åº”æ¨¡å‹"""
    task_id: str
    status: str
    message: str

class VideoService:
    def __init__(self):
        self.comfyui_api_url = "http://192.168.1.246:5001"  # ComfyUI APIåŒ…è£…å™¨åœ°å€
        self.comfyui_direct_url = "http://192.168.1.246:8188"  # ç›´æ¥ComfyUIåœ°å€ï¼ˆå¤‡ç”¨ï¼‰
        self.comfyui_url = self.comfyui_direct_url  # ç”¨äºè§†é¢‘ä¸‹è½½çš„URL

    async def generate_video(self, request: VideoRequest):
        """ç”Ÿæˆè§†é¢‘ - å¼ºåˆ¶ä½¿ç”¨4æ­¥LoRAä¼˜åŒ–å·¥ä½œæµ"""
        print(f"æ”¶åˆ°è§†é¢‘ç”Ÿæˆè¯·æ±‚: provider={request.provider}, prompt={request.prompt[:50]}...")

        try:
            # å¼ºåˆ¶ä½¿ç”¨4æ­¥LoRAä¼˜åŒ–å·¥ä½œæµï¼ˆè·³è¿‡APIåŒ…è£…å™¨é»˜è®¤å‚æ•°ï¼‰
            print("ğŸš€ å¼ºåˆ¶ä½¿ç”¨4æ­¥LoRAä¼˜åŒ–å·¥ä½œæµï¼ˆè·³è¿‡APIåŒ…è£…å™¨é»˜è®¤å‚æ•°ï¼‰")
            return await self._generate_via_direct_comfyui(request)

            # åŸæ¥çš„ä»£ç ï¼šå…ˆå°è¯•APIåŒ…è£…å™¨ï¼Œå¤±è´¥åä½¿ç”¨ç›´æ¥è°ƒç”¨
            # # ä¼˜å…ˆä½¿ç”¨APIåŒ…è£…å™¨
            # video_info = await self._generate_via_api_wrapper(request)
            # if video_info:
            #     return video_info

            # print("APIåŒ…è£…å™¨å¤±è´¥ï¼Œå°è¯•ç›´æ¥è°ƒç”¨ComfyUI...")
            # # å¦‚æœAPIåŒ…è£…å™¨å¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥è°ƒç”¨
            # return await self._generate_via_direct_comfyui(request)

        except Exception as e:
            print(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None

    async def _generate_via_api_wrapper(self, request: VideoRequest):
        """é€šè¿‡APIåŒ…è£…å™¨ç”Ÿæˆè§†é¢‘"""
        try:
            print(f"ğŸŒ è°ƒç”¨ComfyUI APIåŒ…è£…å™¨: {self.comfyui_api_url}")

            # æ„å»ºAPIåŒ…è£…å™¨è¯·æ±‚
            api_request = {
                "prompt": request.prompt,
                "width": request.width,
                "height": request.height,
                "duration": request.duration,
                "fps": request.fps,
                "seed": request.seed,
                "negative_prompt": "static, still, frozen, motionless, blurry, low quality, distorted, watermark, text, error, ugly, deformed"
            }

            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=600)) as session:
                # æäº¤è§†é¢‘ç”Ÿæˆä»»åŠ¡
                async with session.post(f"{self.comfyui_api_url}/api/generate_video", json=api_request) as response:
                    if response.status != 200:
                        print(f"APIåŒ…è£…å™¨è¯·æ±‚å¤±è´¥: {response.status}")
                        return None

                    result = await response.json()
                    # APIåŒ…è£…å™¨æˆåŠŸçŠ¶æ€ï¼šstatusä¸º"submitted"æˆ–å­˜åœ¨task_id
                    if result.get("status") != "submitted" and not result.get("task_id"):
                        print(f"APIåŒ…è£…å™¨è¿”å›é”™è¯¯: {result.get('message', 'unknown error')}")
                        return None

                    task_id = result.get("task_id")
                    if not task_id:
                        print("APIåŒ…è£…å™¨æœªè¿”å›task_id")
                        return None

            print(f"âœ… APIåŒ…è£…å™¨ä»»åŠ¡å·²åˆ›å»º: {task_id}")
            print(f"å¼€å§‹ç›‘æ§ä»»åŠ¡ {task_id}...")

            # ç›‘æ§ä»»åŠ¡è¿›åº¦
            return await self._monitor_api_wrapper_task(task_id, request)

        except Exception as e:
            print(f"APIåŒ…è£…å™¨è°ƒç”¨å¤±è´¥: {str(e)}")
            return None

    async def _monitor_api_wrapper_task(self, task_id: str, request: VideoRequest):
        """ç›‘æ§APIåŒ…è£…å™¨ä»»åŠ¡è¿›åº¦"""
        try:
            max_wait_time = 600  # 10åˆ†é’Ÿè¶…æ—¶
            check_interval = 5   # 5ç§’æ£€æŸ¥ä¸€æ¬¡
            elapsed_time = 0

            async with aiohttp.ClientSession() as session:
                while elapsed_time < max_wait_time:
                    # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
                    async with session.get(f"{self.comfyui_api_url}/api/task_status/{task_id}") as response:
                        if response.status == 200:
                            status_data = await response.json()
                            status = status_data.get("status", "unknown")

                            print(f"ä»»åŠ¡çŠ¶æ€: {status} (å·²ç­‰å¾… {elapsed_time}s)")

                            if status == "completed":
                                # ä»»åŠ¡å®Œæˆï¼Œè·å–è§†é¢‘ä¿¡æ¯
                                video_info = await self._get_completed_video_info(session, task_id)
                                if video_info:
                                    print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ!")
                                    print(f"   æ–‡ä»¶: {video_info.get('filename', 'unknown')}")
                                    print(f"   è€—æ—¶: {elapsed_time}ç§’")
                                    print(f"   æ–‡ä»¶å¤§å°: {video_info.get('file_size', 0)} bytes")

                                    # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œå¦‚æœå¤ªå°å¯èƒ½ç”Ÿæˆä¸å®Œæ•´
                                    file_size = video_info.get('file_size', 0)
                                    if file_size < 5000:  # å°äº5KBå¯èƒ½æœ‰é—®é¢˜
                                        print(f"   âš ï¸ è­¦å‘Š: MP4æ–‡ä»¶è¿‡å°ï¼Œå¯èƒ½ç”Ÿæˆä¸å®Œæ•´")

                                return video_info

                            elif status == "failed":
                                error_msg = status_data.get("error", "æœªçŸ¥é”™è¯¯")
                                print(f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}")
                                return None

                            elif status in ["pending", "processing"]:
                                # ç»§ç»­ç­‰å¾…
                                pass

                            else:
                                print(f"æœªçŸ¥çŠ¶æ€: {status}")

                        await asyncio.sleep(check_interval)
                        elapsed_time += check_interval

            print(f"â° ä»»åŠ¡è¶…æ—¶ ({max_wait_time}ç§’)")
            return None

        except Exception as e:
            print(f"ç›‘æ§ä»»åŠ¡å¤±è´¥: {str(e)}")
            return None

    async def _get_completed_video_info(self, session: aiohttp.ClientSession, task_id: str):
        """è·å–å®Œæˆçš„è§†é¢‘ä¿¡æ¯"""
        try:
            async with session.get(f"{self.comfyui_api_url}/api/download_video/{task_id}") as response:
                if response.status == 200:
                    # è·å–è§†é¢‘æ–‡ä»¶ä¿¡æ¯
                    content_length = response.headers.get('content-length', '0')
                    content_disposition = response.headers.get('content-disposition', '')

                    # ä»Content-Dispositionä¸­æå–æ–‡ä»¶å
                    filename = f"wan_video_{task_id[:8]}_.mp4"
                    if 'filename=' in content_disposition:
                        filename = content_disposition.split('filename=')[-1].strip('"')

                    return {
                        "filename": filename,
                        "file_path": f"/tmp/{filename}",  # APIåŒ…è£…å™¨çš„è§†é¢‘å­˜å‚¨è·¯å¾„
                        "file_size": int(content_length),
                        "task_id": task_id,
                        "download_url": f"{self.comfyui_api_url}/api/download_video/{task_id}"
                    }
                else:
                    print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {response.status}")
                    return None
        except Exception as e:
            print(f"è·å–è§†é¢‘ä¿¡æ¯å¼‚å¸¸: {str(e)}")
            return None

    async def _generate_via_direct_comfyui(self, request: VideoRequest):
        """ç›´æ¥è°ƒç”¨ComfyUIï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            print(f"ğŸ¯ ç›´æ¥è°ƒç”¨ComfyUI: {self.comfyui_direct_url}")

            # åˆ›å»ºä¼˜åŒ–çš„å·¥ä½œæµ
            workflow = self._create_optimized_workflow(request)

            # æäº¤åˆ°ComfyUI
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(f"{self.comfyui_direct_url}/prompt", json={
                    "prompt": workflow
                })
                response.raise_for_status()
                result = response.json()
                task_id = result.get("prompt_id")

            print(f"ComfyUIä»»åŠ¡å·²åˆ›å»º: {task_id}")
            print(f"å¼€å§‹ç›‘æ§ä»»åŠ¡ {task_id}...")

            # ç›‘æ§ä»»åŠ¡è¿›åº¦
            return await self._monitor_direct_task(task_id, request)

        except Exception as e:
            print(f"ç›´æ¥ComfyUIè°ƒç”¨å¤±è´¥: {str(e)}")
            return None

    async def _monitor_direct_task(self, task_id: str, request: VideoRequest):
        """ç›‘æ§ç›´æ¥ComfyUIä»»åŠ¡è¿›åº¦"""
        start_time = asyncio.get_event_loop().time()

        while True:
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(f"{self.comfyui_direct_url}/history/{task_id}")
                    response.raise_for_status()
                    history = response.json()

                if task_id in history:
                    task_data = history[task_id]
                    status = task_data.get("status", {})

                    if status.get("completed", False):
                        print(f"âœ… ç›´æ¥ComfyUIä»»åŠ¡å®Œæˆ!")
                        return await self._extract_video_info(task_data, start_time)

                    elapsed = asyncio.get_event_loop().time() - start_time
                    print(f"â³ ç›´æ¥ComfyUIä»»åŠ¡è¿›è¡Œä¸­... ({elapsed:.1f}ç§’)")

                await asyncio.sleep(3)

                # è¶…æ—¶æ£€æŸ¥
                if asyncio.get_event_loop().time() - start_time > 600:  # 10åˆ†é’Ÿè¶…æ—¶
                    print(f"â° ç›´æ¥ComfyUIä»»åŠ¡è¶…æ—¶")
                    return None

            except Exception as e:
                print(f"âš ï¸ ç›‘æ§ç›´æ¥ComfyUIä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
                await asyncio.sleep(3)
                continue

    def _create_optimized_workflow(self, request: VideoRequest):
        """åˆ›å»º4æ­¥LoRAä¼˜åŒ–çš„å·¥ä½œæµ"""
        # ä¼˜åŒ–prompt
        optimized_prompt = self._optimize_prompt(request.prompt)

        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        filename_prefix = f"wan_video_{uuid.uuid4().hex[:8]}"

        # ä½¿ç”¨640x640ä½œä¸ºé»˜è®¤åˆ†è¾¨ç‡ï¼ˆæ›´é«˜çš„è´¨é‡ï¼‰
        width = min(max(640, min(request.width, 1024)), 1024)
        height = min(max(640, min(request.height, 1024)), 1024)

        # 81å¸§ï¼ˆ5ç§’@16fpsï¼‰- ä¼˜åŒ–çš„å¸§æ•°
        num_frames = 81

        # 4æ­¥LoRAä¼˜åŒ–å‚æ•°
        steps = 4
        cfg = 1.0
        shift = 5.0

        workflow = {
            "71": {  # CLIPLoader
                "inputs": {
                    "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
                    "type": "wan",
                    "device": "default"
                },
                "class_type": "CLIPLoader"
            },
            "73": {  # VAELoader
                "inputs": {
                    "vae_name": "wan_2.1_vae.safetensors"
                },
                "class_type": "VAELoader"
            },
            "75": {  # UNETLoader - High Noise
                "inputs": {
                    "unet_name": "wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors",
                    "weight_dtype": "default"
                },
                "class_type": "UNETLoader"
            },
            "83": {  # LoraLoaderModelOnly - 4æ­¥LoRA
                "inputs": {
                    "model": ["75", 0],
                    "lora_name": "wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors",
                    "strength_model": 1.0
                },
                "class_type": "LoraLoaderModelOnly"
            },
            "86": {  # ModelSamplingSD3 - ä¼˜åŒ–shift
                "inputs": {
                    "model": ["83", 0],
                    "shift": shift
                },
                "class_type": "ModelSamplingSD3"
            },
            "89": {  # CLIPTextEncode - Positive
                "inputs": {
                    "clip": ["71", 0],
                    "text": optimized_prompt
                },
                "class_type": "CLIPTextEncode"
            },
            "72": {  # CLIPTextEncode - Negative
                "inputs": {
                    "clip": ["71", 0],
                    "text": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°ï¼Œè£¸éœ²ï¼ŒNSFW"
                },
                "class_type": "CLIPTextEncode"
            },
            "74": {  # EmptyHunyuanLatentVideo
                "inputs": {
                    "width": width,
                    "height": height,
                    "length": num_frames,
                    "batch_size": 1
                },
                "class_type": "EmptyHunyuanLatentVideo"
            },
            "81": {  # KSamplerAdvanced - ç¬¬ä¸€é˜¶æ®µ4æ­¥
                "inputs": {
                    "model": ["86", 0],
                    "positive": ["89", 0],
                    "negative": ["72", 0],
                    "latent_image": ["74", 0],
                    "add_noise": "enable",
                    "noise_seed": request.seed or random.randint(1, 2**31),
                    "steps": steps,
                    "cfg": cfg,
                    "sampler_name": "euler",
                    "scheduler": "simple",
                    "start_at_step": 0,
                    "end_at_step": steps,
                    "return_with_leftover_noise": "disable"
                },
                "class_type": "KSamplerAdvanced"
            },
            "87": {  # VAEDecode
                "inputs": {
                    "samples": ["81", 0],
                    "vae": ["73", 0]
                },
                "class_type": "VAEDecode"
            },
            "88": {  # CreateVideo
                "inputs": {
                    "images": ["87", 0],
                    "fps": min(max(request.fps, 12), 24),
                    "audio": None
                },
                "class_type": "CreateVideo"
            },
            "80": {  # SaveVideo
                "inputs": {
                    "video": ["88", 0],
                    "filename_prefix": filename_prefix,  # ç§»é™¤video/å‰ç¼€
                    "format": "auto",
                    "codec": "auto"
                },
                "class_type": "SaveVideo"
            }
        }

        print(f"âœ… åˆ›å»º4æ­¥LoRAä¼˜åŒ–å·¥ä½œæµï¼Œå‚æ•°:")
        print(f"   åˆ†è¾¨ç‡: {width}x{height}")
        print(f"   å¸§æ•°: {num_frames}")
        print(f"   æ­¥æ•°: {steps} (4æ­¥LoRAä¼˜åŒ–)")
        print(f"   CFG: {cfg} (LoRAä¼˜åŒ–)")
        print(f"   Shift: {shift}")
        print(f"   LoRA: wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors")

        return workflow

    def _optimize_prompt(self, prompt: str) -> str:
        """ä¼˜åŒ–promptï¼Œç¡®ä¿åœºæ™¯é¦–å°¾ç›¸æ¥"""
        if not prompt:
            return "ç¾ä¸½çš„é£æ™¯ï¼ŒåŠ¨æ€æµç•…ï¼Œé«˜è´¨é‡"

        # å¦‚æœpromptæ²¡æœ‰åŒ…å«å¾ªç¯/é¦–å°¾ç›¸æ¥çš„æè¿°ï¼Œæ·»åŠ ç›¸å…³è¯æ±‡
        loop_keywords = ["å¾ªç¯", "é¦–å°¾ç›¸æ¥", "æ— ç¼", "seamless", "loop", "è¿ç»­"]
        if not any(keyword in prompt for keyword in loop_keywords):
            prompt += "ï¼Œåœºæ™¯è‡ªç„¶è¿‡æ¸¡ï¼Œé¦–å°¾ç›¸æ¥"

        return prompt

    async def _monitor_task(self, task_id: str, request: VideoRequest):
        """ç›‘æ§ComfyUIä»»åŠ¡è¿›åº¦"""
        start_time = asyncio.get_event_loop().time()

        while True:
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(f"{self.comfyui_url}/history/{task_id}")
                    response.raise_for_status()
                    history = response.json()

                if task_id in history:
                    task_data = history[task_id]
                    status = task_data.get("status", {})

                    if status.get("completed", False):
                        print(f"âœ… ä»»åŠ¡å®Œæˆ!")
                        return await self._extract_video_info(task_data, start_time)

                    elapsed = asyncio.get_event_loop().time() - start_time
                    print(f"â³ ä»»åŠ¡è¿›è¡Œä¸­... ({elapsed:.1f}ç§’)")

                await asyncio.sleep(3)

                # è¶…æ—¶æ£€æŸ¥
                if asyncio.get_event_loop().time() - start_time > 600:  # 10åˆ†é’Ÿè¶…æ—¶
                    print(f"â° ä»»åŠ¡è¶…æ—¶")
                    return None

            except Exception as e:
                print(f"âš ï¸ ç›‘æ§ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
                await asyncio.sleep(3)
                continue

    async def _extract_video_info(self, task_data: dict, start_time: float):
        """æå–è§†é¢‘ä¿¡æ¯"""
        try:
            outputs = task_data.get("outputs", {})
            for node_id, output in outputs.items():
                # æ£€æŸ¥videosæˆ–imagesè¾“å‡º
                videos = output.get("videos", [])
                images = output.get("images", [])

                files = videos if videos else images
                if files:
                    file = files[0]
                    filename = file.get("filename", "")

                    # ä¸‹è½½è§†é¢‘æ–‡ä»¶åˆ°æœ¬åœ°
                    local_file_path = await self._download_video_locally(filename)

                    generation_time = asyncio.get_event_loop().time() - start_time

                    # è·å–æœ¬åœ°æ–‡ä»¶å¤§å°
                    file_size = 0
                    if local_file_path and local_file_path.exists():
                        file_size = local_file_path.stat().st_size

                    print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ!")
                    print(f"   æ–‡ä»¶: {filename}")
                    if local_file_path:
                        print(f"   æœ¬åœ°è·¯å¾„: {local_file_path}")
                    print(f"   è€—æ—¶: {generation_time:.1f}ç§’")
                    print(f"   æ–‡ä»¶å¤§å°: {file_size:,} bytes")

                    if file_size > 0:
                        if file_size > 500000:  # 500KB
                            print(f"   âœ… æ–‡ä»¶å¤§å°å¾ˆå¥½ï¼Œåº”è¯¥æ˜¯é«˜è´¨é‡è§†é¢‘")
                        elif file_size > 100000:  # 100KB
                            print(f"   âœ… æ–‡ä»¶å¤§å°è‰¯å¥½ï¼Œåº”è¯¥æ˜¯æ­£å¸¸è§†é¢‘")
                        elif file_size > 10000:  # 10KB
                            print(f"   âš ï¸ æ–‡ä»¶è¾ƒå°ï¼Œå¯èƒ½æ˜¯ä½è´¨é‡æˆ–çŸ­æ—¶é•¿çš„è§†é¢‘")
                        else:
                            print(f"   âš ï¸ è­¦å‘Š: MP4æ–‡ä»¶è¿‡å°ï¼Œå¯èƒ½ç”Ÿæˆä¸å®Œæ•´")

                    return {
                        "filename": filename,
                        "local_file_path": str(local_file_path) if local_file_path else None,
                        "file_size": file_size,
                        "generation_time": generation_time
                    }

            print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘è¾“å‡º")
            return None

        except Exception as e:
            print(f"âŒ æå–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    async def _download_video_locally(self, filename: str):
        """ä»ComfyUIæœåŠ¡å™¨ä¸‹è½½è§†é¢‘æ–‡ä»¶åˆ°æœ¬åœ°"""
        try:
            print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½è§†é¢‘æ–‡ä»¶: {filename}")

            # æ„å»ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
            local_file_path = LOCAL_VIDEO_DIR / filename

            # å¦‚æœæœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
            if local_file_path.exists():
                print(f"   æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨: {local_file_path}")
                return local_file_path

            # ä»ComfyUIæœåŠ¡å™¨ä¸‹è½½
            download_url = f"{self.comfyui_url}/view"
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.get(download_url, params={"filename": filename})

                if response.status_code == 200:
                    # ä¿å­˜åˆ°æœ¬åœ°
                    local_file_path.write_bytes(response.content)
                    file_size = local_file_path.stat().st_size

                    print(f"   âœ… è§†é¢‘ä¸‹è½½æˆåŠŸ!")
                    print(f"   æœ¬åœ°è·¯å¾„: {local_file_path}")
                    print(f"   æ–‡ä»¶å¤§å°: {file_size:,} bytes")

                    return local_file_path
                else:
                    print(f"   âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                    return None

        except Exception as e:
            print(f"   âŒ ä¸‹è½½è§†é¢‘å¤±è´¥: {str(e)}")
            return None

video_service = VideoService()

# ==================== æ–‡æœ¬ä¼˜åŒ–æœåŠ¡ ====================

class TextOptimizeService:
    def __init__(self):
        # è¿™é‡Œå¯ä»¥é…ç½®å„ç§LLM APIå¯†é’¥
        self.providers = {
            "glm": {
                "name": "GLM-4.6",
                "available": True
            },
            "kimi": {
                "name": "Kimi",
                "available": True
            },
            "doubao": {
                "name": "è±†åŒ…",
                "available": True
            }
        }

    async def optimize_text(self, text: str, provider: str = "glm", custom_prompt: str = ""):
        """ä¼˜åŒ–æ–‡æœ¬ - ä½¿ç”¨çœŸå®LLM API"""
        print(f"æ”¶åˆ°æ–‡æœ¬ä¼˜åŒ–è¯·æ±‚: provider={provider}, text={text[:50]}...")
        if custom_prompt:
            print(f"ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯: {custom_prompt[:100]}...")

        try:
            # æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦å¯ç”¨
            if llm_service is None:
                print("âš ï¸ LLMæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿä¼˜åŒ–")
                # å›é€€åˆ°æ¨¡æ‹Ÿä¼˜åŒ–
                optimized_text = f"[{provider.upper()}ä¼˜åŒ–] {text}ï¼Œå¢å¼ºè¡¨ç°åŠ›ï¼Œæ›´åŠ ç”ŸåŠ¨æœ‰è¶£ï¼Œé€‚åˆå†…å®¹åˆ›ä½œã€‚"
                await asyncio.sleep(1)
                return {
                    "optimized_text": optimized_text,
                    "provider": provider,
                    "original_text": text,
                    "source": "simulation"
                }

            # ä½¿ç”¨çœŸå®LLMæœåŠ¡è¿›è¡Œä¼˜åŒ–
            print(f"ğŸš€ ä½¿ç”¨çœŸå®LLMæœåŠ¡ä¼˜åŒ–æ–‡æœ¬...")

            # è½¬æ¢provideråç§°åˆ°LLMProvideræšä¸¾
            provider_map = {
                "glm": LLMProvider.GLM,
                "kimi": LLMProvider.KIMI,
                "doubao": LLMProvider.DOUBAO,
                "openai": LLMProvider.OPENAI,
                "qwen": LLMProvider.QWEN,
                "wenxin": LLMProvider.WENXIN
            }

            llm_provider = provider_map.get(provider, LLMProvider.GLM)

            # å¦‚æœæœ‰è‡ªå®šä¹‰æç¤ºè¯ï¼Œä½¿ç”¨é€šç”¨LLMç”Ÿæˆæ–¹æ³•ï¼›å¦åˆ™ä½¿ç”¨ä¸“é—¨çš„è§†é¢‘ä¼˜åŒ–æ–¹æ³•
            if custom_prompt:
                # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯è¿›è¡Œä¼˜åŒ–
                from services.llm.llm_service import LLMRequest, Message
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œå°†è‡ªå®šä¹‰æç¤ºè¯ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
                full_prompt = custom_prompt.replace("{original_text}", text)
                messages = [
                    Message(role="user", content=full_prompt)
                ]
                request = LLMRequest(
                    messages=messages,
                    provider=llm_provider
                )
                response = await llm_service.generate_text(request)
                optimized_text = response.content
            else:
                # è°ƒç”¨çœŸå®çš„LLMæ–‡æœ¬ä¼˜åŒ–ï¼ˆè§†é¢‘ä¼˜åŒ–æ¨¡å¼ï¼‰
                optimized_text = await llm_service.optimize_text_for_video(text, llm_provider)

            print(f"âœ… LLMæ–‡æœ¬ä¼˜åŒ–å®Œæˆ")

            return {
                "optimized_text": optimized_text,
                "provider": provider,
                "original_text": text,
                "source": "llm_api"
            }

        except Exception as e:
            print(f"âŒ LLMæ–‡æœ¬ä¼˜åŒ–å¤±è´¥: {str(e)}")
            print(f"ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿä¼˜åŒ–...")

            # å›é€€åˆ°æ¨¡æ‹Ÿä¼˜åŒ–
            try:
                optimized_text = f"[{provider.upper()}ä¼˜åŒ–] {text}ï¼Œå¢å¼ºè¡¨ç°åŠ›ï¼Œæ›´åŠ ç”ŸåŠ¨æœ‰è¶£ï¼Œé€‚åˆå†…å®¹åˆ›ä½œã€‚"
                await asyncio.sleep(1)

                return {
                    "optimized_text": optimized_text,
                    "provider": provider,
                    "original_text": text,
                    "source": "fallback"
                }
            except Exception as fallback_error:
                print(f"âŒ å›é€€ä¼˜åŒ–ä¹Ÿå¤±è´¥: {str(fallback_error)}")
                return None

text_optimize_service = TextOptimizeService()

# ==================== çˆ¬è™«æœåŠ¡ ====================

class SpiderService:
    def __init__(self):
        self.platforms = {
            "csdn": {"name": "CSDN", "available": True},
            "juejin": {"name": "æ˜é‡‘", "available": True},
            "zhihu": {"name": "çŸ¥ä¹", "available": True},
            "toutiao": {"name": "å¤´æ¡", "available": True}
        }
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }

    async def crawl_article(self, platform: str, url: str):
        """çœŸå®çˆ¬å–æ–‡ç« """
        print(f"æ”¶åˆ°çˆ¬è™«è¯·æ±‚: platform={platform}, url={url}")

        try:
            # ä½¿ç”¨aiohttpè·å–ç½‘é¡µå†…å®¹
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(headers=self.headers, timeout=timeout) as session:
                print(f"æ­£åœ¨æŠ“å–é¡µé¢: {url}")
                async with session.get(url) as response:
                    if response.status == 200:
                        html = await response.text()
                        print(f"é¡µé¢è·å–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(html)}")

                        # è§£æé¡µé¢å†…å®¹
                        article_data = await self.parse_article_content(html, url, platform)
                        print(f"çˆ¬è™«å®Œæˆ: {article_data.get('title', 'unknown')}")
                        return article_data
                    else:
                        print(f"é¡µé¢è·å–å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return self.create_error_response(url, platform, f"HTTP {response.status}")

        except asyncio.TimeoutError:
            print(f"çˆ¬è™«è¶…æ—¶: {url}")
            return self.create_error_response(url, platform, "è¯·æ±‚è¶…æ—¶")
        except Exception as e:
            print(f"çˆ¬è™«å¤±è´¥: {str(e)}")
            return self.create_error_response(url, platform, str(e))

    async def parse_article_content(self, html: str, url: str, platform: str):
        """è§£ææ–‡ç« å†…å®¹"""
        try:
            soup = BeautifulSoup(html, 'html.parser')

            # æ ¹æ®ä¸åŒå¹³å°ä½¿ç”¨ä¸åŒçš„è§£æç­–ç•¥
            if platform == "csdn":
                return await self.parse_csdn_article(soup, url)
            elif platform == "juejin":
                return await self.parse_juejin_article(soup, url)
            elif platform == "zhihu":
                return await self.parse_zhihu_article(soup, url)
            else:
                return await self.parse_general_article(soup, url, platform)

        except Exception as e:
            print(f"è§£ææ–‡ç« å¤±è´¥: {str(e)}")
            return self.create_error_response(url, platform, f"è§£æå¤±è´¥: {str(e)}")

    async def parse_csdn_article(self, soup: BeautifulSoup, url: str):
        """è§£æCSDNæ–‡ç« """
        # æå–æ ‡é¢˜
        title_elem = soup.find('h1', class_='article-title')
        if not title_elem:
            title_elem = soup.find('title')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"

        # æå–ä½œè€…
        author_elem = soup.find('a', class_='author')
        if not author_elem:
            author_elem = soup.find('span', class_='author-name')
        author = author_elem.get_text().strip() if author_elem else "æœªçŸ¥ä½œè€…"

        # æå–å‘å¸ƒæ—¶é—´
        time_elem = soup.find('span', class_='time')
        if not time_elem:
            time_elem = soup.find('div', class_='article-info-box').find('span') if soup.find('div', class_='article-info-box') else None
        publish_time = time_elem.get_text().strip() if time_elem else datetime.now().strftime('%Y-%m-%d')

        # æå–å†…å®¹
        content_elem = soup.find('div', class_='article-content')
        if not content_elem:
            content_elem = soup.find('div', id='content_views')
        if not content_elem:
            content_elem = soup.find('article')

        content = ""
        if content_elem:
            # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
            for tag in content_elem.find_all(['script', 'style', 'nav', 'footer', 'aside']):
                tag.decompose()
            content = content_elem.get_text().strip()

        # æå–æ ‡ç­¾
        tags = []
        tag_elems = soup.find_all('a', class_='tag')
        for tag_elem in tag_elems:
            tag_text = tag_elem.get_text().strip()
            if tag_text:
                tags.append(tag_text)

        # æå–é˜…è¯»é‡
        read_count = 0
        read_elem = soup.find('span', class_='read-count')
        if read_elem:
            try:
                read_text = read_elem.get_text().strip()
                read_num = re.findall(r'\d+', read_text)
                if read_num:
                    read_count = int(read_num[0])
            except:
                pass

        # ç”Ÿæˆå†…å®¹æ‘˜è¦
        summary = content[:200] + "..." if len(content) > 200 else content

        return {
            "title": title,
            "content": content,
            "summary": summary,
            "author": author,
            "publish_time": publish_time,
            "url": url,
            "platform": "csdn",
            "tags": tags,
            "read_count": read_count,
            "like_count": 0,
            "crawl_time": datetime.now().isoformat(),
            "word_count": len(content),
            "status": "success"
        }

    async def parse_juejin_article(self, soup: BeautifulSoup, url: str):
        """è§£ææ˜é‡‘æ–‡ç« """
        # æå–æ ‡é¢˜
        title_elem = soup.find('h1', class_='article-title')
        if not title_elem:
            title_elem = soup.find('title')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"

        # æå–ä½œè€…
        author_elem = soup.find('a', class_='username')
        if not author_elem:
            author_elem = soup.find('span', class_='user-name')
        author = author_elem.get_text().strip() if author_elem else "æœªçŸ¥ä½œè€…"

        # æå–å‘å¸ƒæ—¶é—´
        time_elem = soup.find('time')
        publish_time = time_elem.get_text().strip() if time_elem else datetime.now().strftime('%Y-%m-%d')

        # æå–å†…å®¹
        content_elem = soup.find('div', class_='article-content')
        if not content_elem:
            content_elem = soup.find('div', class_='markdown-body')

        content = ""
        if content_elem:
            for tag in content_elem.find_all(['script', 'style', 'nav', 'footer', 'aside']):
                tag.decompose()
            content = content_elem.get_text().strip()

        # æå–æ ‡ç­¾
        tags = []
        tag_elems = soup.find_all('a', class_='tag')
        for tag_elem in tag_elems:
            tag_text = tag_elem.get_text().strip()
            if tag_text:
                tags.append(tag_text)

        # ç”Ÿæˆæ‘˜è¦
        summary = content[:200] + "..." if len(content) > 200 else content

        return {
            "title": title,
            "content": content,
            "summary": summary,
            "author": author,
            "publish_time": publish_time,
            "url": url,
            "platform": "juejin",
            "tags": tags,
            "read_count": 0,
            "like_count": 0,
            "crawl_time": datetime.now().isoformat(),
            "word_count": len(content),
            "status": "success"
        }

    async def parse_zhihu_article(self, soup: BeautifulSoup, url: str):
        """è§£æçŸ¥ä¹æ–‡ç« """
        # æå–æ ‡é¢˜
        title_elem = soup.find('h1', class_='Post-Title')
        if not title_elem:
            title_elem = soup.find('h1')
        if not title_elem:
            title_elem = soup.find('title')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"

        # æå–ä½œè€…
        author_elem = soup.find('span', class_='UserLink-link')
        if not author_elem:
            author_elem = soup.find('a', class_='author-link')
        author = author_elem.get_text().strip() if author_elem else "æœªçŸ¥ä½œè€…"

        # æå–å‘å¸ƒæ—¶é—´
        time_elem = soup.find('time')
        publish_time = time_elem.get_text().strip() if time_elem else datetime.now().strftime('%Y-%m-%d')

        # æå–å†…å®¹
        content_elem = soup.find('div', class_='Post-RichText')
        if not content_elem:
            content_elem = soup.find('div', class_='RichText')

        content = ""
        if content_elem:
            for tag in content_elem.find_all(['script', 'style', 'nav', 'footer', 'aside']):
                tag.decompose()
            content = content_elem.get_text().strip()

        # ç”Ÿæˆæ‘˜è¦
        summary = content[:200] + "..." if len(content) > 200 else content

        return {
            "title": title,
            "content": content,
            "summary": summary,
            "author": author,
            "publish_time": publish_time,
            "url": url,
            "platform": "zhihu",
            "tags": [],
            "read_count": 0,
            "like_count": 0,
            "crawl_time": datetime.now().isoformat(),
            "word_count": len(content),
            "status": "success"
        }

    async def parse_general_article(self, soup: BeautifulSoup, url: str, platform: str):
        """é€šç”¨æ–‡ç« è§£æ"""
        # æå–æ ‡é¢˜
        title_elem = soup.find('title')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"

        # æå–å†…å®¹ - é€šç”¨æ–¹æ³•
        content = ""

        # å°è¯•å¤šç§å¸¸è§çš„å†…å®¹é€‰æ‹©å™¨
        content_selectors = [
            'article',
            '.article-content',
            '.post-content',
            '.entry-content',
            '.content',
            '#content',
            '.main-content',
            'main'
        ]

        for selector in content_selectors:
            content_elem = soup.select_one(selector)
            if content_elem:
                # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
                for tag in content_elem.find_all(['script', 'style', 'nav', 'footer', 'aside', 'header']):
                    tag.decompose()
                content = content_elem.get_text().strip()
                if len(content) > 100:  # å†…å®¹é•¿åº¦åˆç†
                    break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å†…å®¹ï¼Œå°è¯•è·å–bodyæ–‡æœ¬
        if not content:
            body_elem = soup.find('body')
            if body_elem:
                for tag in body_elem.find_all(['script', 'style', 'nav', 'footer', 'aside', 'header']):
                    tag.decompose()
                content = body_elem.get_text().strip()

        # ç”Ÿæˆæ‘˜è¦
        summary = content[:200] + "..." if len(content) > 200 else content

        return {
            "title": title,
            "content": content,
            "summary": summary,
            "author": "æœªçŸ¥ä½œè€…",
            "publish_time": datetime.now().strftime('%Y-%m-%d'),
            "url": url,
            "platform": platform,
            "tags": [],
            "read_count": 0,
            "like_count": 0,
            "crawl_time": datetime.now().isoformat(),
            "word_count": len(content),
            "status": "success"
        }

    def create_error_response(self, url: str, platform: str, error_msg: str):
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return {
            "title": f"çˆ¬å–å¤±è´¥",
            "content": f"æ— æ³•çˆ¬å–æ–‡ç« å†…å®¹ã€‚é”™è¯¯ï¼š{error_msg}ã€‚URL: {url}",
            "summary": "çˆ¬å–å¤±è´¥",
            "author": "æœªçŸ¥",
            "publish_time": datetime.now().strftime('%Y-%m-%d'),
            "url": url,
            "platform": platform,
            "tags": [],
            "read_count": 0,
            "like_count": 0,
            "crawl_time": datetime.now().isoformat(),
            "word_count": 0,
            "status": "failed",
            "error": error_msg
        }

spider_service = SpiderService()

# ==================== APIç«¯ç‚¹ ====================

@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "ai-media-platform"}

# è§†é¢‘ç”ŸæˆAPI
@app.post("/api/v1/video/generate")
async def generate_video(request: dict):
    """ç”Ÿæˆè§†é¢‘API"""
    try:
        # è§£æè¯·æ±‚æ•°æ®
        video_request = VideoRequest(
            provider=request.get("provider", "comfyui_wan"),
            prompt=request.get("prompt", ""),
            duration=request.get("duration", 8),
            width=request.get("width", 512),
            height=request.get("height", 512),
            fps=request.get("fps", 16),
            seed=request.get("seed")
        )

        # ç”Ÿæˆè§†é¢‘
        video_info = await video_service.generate_video(video_request)

        if video_info:
            # æ·»åŠ æœ¬åœ°è§†é¢‘URL
            if video_info.get("local_file_path"):
                # ä»å®Œæ•´è·¯å¾„ä¸­æå–æ–‡ä»¶å
                local_file_path = Path(video_info["local_file_path"])
                video_url = f"http://localhost:9000/api/v1/video/file/{local_file_path.name}"
                video_info["local_video_url"] = video_url
                print(f"ğŸ¬ æœ¬åœ°è§†é¢‘URL: {video_url}")

            return {
                "success": True,
                "data": {
                    "video_info": video_info
                }
            }
        else:
            return {
                "success": False,
                "message": "è§†é¢‘ç”Ÿæˆå¤±è´¥"
            }

    except Exception as e:
        print(f"APIé”™è¯¯: {str(e)}")
        return {
            "success": False,
            "message": f"APIé”™è¯¯: {str(e)}"
        }

@app.get("/api/v1/video/providers")
async def get_providers():
    """è·å–è§†é¢‘ç”Ÿæˆæä¾›å•†åˆ—è¡¨"""
    return {
        "success": True,
        "data": {
            "providers": [
                {
                    "id": "comfyui_wan",
                    "name": "ComfyUI Wan 2.2",
                    "description": "åŸºäºComfyUIçš„Wan 2.2è§†é¢‘ç”Ÿæˆæ¨¡å‹",
                    "status": "available"
                }
            ]
        }
    }

# æ–‡æœ¬ä¼˜åŒ–API
@app.post("/api/v1/llm/optimize-text")
async def optimize_text(request: dict):
    """æ–‡æœ¬ä¼˜åŒ–API"""
    try:
        text = request.get("text", "")
        provider = request.get("provider", "glm")
        custom_prompt = request.get("custom_prompt", "")

        if not text:
            return {
                "success": False,
                "message": "æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º"
            }

        result = await text_optimize_service.optimize_text(text, provider, custom_prompt)

        if result:
            return {
                "success": True,
                "data": result
            }
        else:
            return {
                "success": False,
                "message": "æ–‡æœ¬ä¼˜åŒ–å¤±è´¥"
            }

    except Exception as e:
        print(f"APIé”™è¯¯: {str(e)}")
        return {
            "success": False,
            "message": f"APIé”™è¯¯: {str(e)}"
        }

@app.get("/api/v1/llm/providers")
async def get_llm_providers():
    """è·å–LLMæä¾›å•†åˆ—è¡¨"""
    return {
        "success": True,
        "data": {
            "providers": [
                {"id": provider_id, "name": info["name"], "available": info["available"]}
                for provider_id, info in text_optimize_service.providers.items()
            ]
        }
    }

# çˆ¬è™«API
@app.post("/api/v1/spider/crawl")
async def crawl_article(request: dict):
    """çˆ¬å–æ–‡ç« API"""
    try:
        # æ”¯æŒä¸¤ç§å‚æ•°æ ¼å¼ï¼š
        # 1. { "platform": "csdn", "url": "..." } - å…¼å®¹æµ‹è¯•æ ¼å¼
        # 2. { "url": "...", "mode": "...", "depth": ..., "filters": [...], "delay": ... } - å‰ç«¯æ ¼å¼

        url = request.get("url", "")

        # å¦‚æœæ²¡æœ‰æä¾›URLï¼Œè¿”å›é”™è¯¯
        if not url:
            return {
                "success": False,
                "message": "URLä¸èƒ½ä¸ºç©º"
            }

        # è‡ªåŠ¨è¯†åˆ«å¹³å°ï¼Œæˆ–è€…ä½¿ç”¨æä¾›çš„platformå‚æ•°
        platform = request.get("platform", "")

        if not platform:
            # æ ¹æ®URLè‡ªåŠ¨è¯†åˆ«å¹³å°
            if "csdn.net" in url:
                platform = "csdn"
            elif "juejin.cn" in url:
                platform = "juejin"
            elif "zhihu.com" in url:
                platform = "zhihu"
            elif "toutiao.com" in url:
                platform = "toutiao"
            elif "xiaohongshu.com" in url:
                platform = "xiaohongshu"
            else:
                platform = "general"  # é€šç”¨çˆ¬è™«

        print(f"çˆ¬è™«è¯·æ±‚: platform={platform}, url={url}")

        result = await spider_service.crawl_article(platform, url)

        if result:
            return {
                "success": True,
                "data": result
            }
        else:
            return {
                "success": False,
                "message": "çˆ¬è™«å¤±è´¥"
            }

    except Exception as e:
        print(f"APIé”™è¯¯: {str(e)}")
        return {
            "success": False,
            "message": f"APIé”™è¯¯: {str(e)}"
        }

@app.get("/api/v1/spider/platforms")
async def get_spider_platforms():
    """è·å–çˆ¬è™«å¹³å°åˆ—è¡¨"""
    return {
        "success": True,
        "data": {
            "platforms": [
                {"id": platform_id, "name": info["name"], "available": info["available"]}
                for platform_id, info in spider_service.platforms.items()
            ]
        }
    }

# ==================== è´¦å·ç®¡ç†æœåŠ¡ ====================

class AccountService:
    def __init__(self):
        # æ¨¡æ‹Ÿè´¦å·æ•°æ®
        self.accounts = [
            {
                "id": 1,
                "platform": "csdn",
                "username": "csdn_developer",
                "status": "active",
                "created_at": "2025-10-01",
                "last_login": "2025-10-07"
            },
            {
                "id": 2,
                "platform": "xiaohongshu",
                "username": "xhs_creator",
                "status": "active",
                "created_at": "2025-10-01",
                "last_login": "2025-10-07"
            },
            {
                "id": 3,
                "platform": "juejin",
                "username": "juejin_dev",
                "status": "inactive",
                "created_at": "2025-10-01",
                "last_login": "2025-10-05"
            }
        ]

    async def get_all_accounts(self):
        """è·å–æ‰€æœ‰è´¦å·"""
        return self.accounts

    async def get_accounts_by_platform(self, platform: str):
        """æ ¹æ®å¹³å°è·å–è´¦å·"""
        return [acc for acc in self.accounts if acc["platform"] == platform]

    async def add_account(self, account_data: dict):
        """æ·»åŠ æ–°è´¦å·"""
        new_account = {
            "id": len(self.accounts) + 1,
            "platform": account_data.get("platform"),
            "username": account_data.get("username"),
            "status": account_data.get("status", "active"),
            "created_at": "2025-10-07",
            "last_login": None
        }
        self.accounts.append(new_account)
        return new_account

account_service = AccountService()

# ==================== ç´ æç®¡ç†æœåŠ¡ ====================

class MaterialService:
    def __init__(self):
        # æ¨¡æ‹Ÿç´ ææ•°æ®
        self.materials = [
            {
                "id": 1,
                "type": "video",
                "title": "AIç”Ÿæˆç§‘æŠ€è§†é¢‘",
                "content": "wan_video_test.mp4",
                "file_size": 2500,
                "tags": ["AI", "ç§‘æŠ€", "è§†é¢‘ç”Ÿæˆ"],
                "created_at": "2025-10-07",
                "source": "comfyui"
            },
            {
                "id": 2,
                "type": "text",
                "title": "ä¼˜åŒ–åçš„æŠ€æœ¯æ–‡ç« ",
                "content": "è¿™æ˜¯ç»è¿‡AIä¼˜åŒ–çš„æŠ€æœ¯æ–‡ç« å†…å®¹...",
                "tags": ["æŠ€æœ¯", "AIä¼˜åŒ–", "æ–‡ç« "],
                "created_at": "2025-10-07",
                "source": "glm"
            },
            {
                "id": 3,
                "type": "image",
                "title": "ç§‘æŠ€æ„Ÿé…å›¾",
                "content": "tech_image.png",
                "file_size": 1024,
                "tags": ["ç§‘æŠ€", "é…å›¾", "AIç”Ÿæˆ"],
                "created_at": "2025-10-07",
                "source": "midjourney"
            }
        ]

    async def get_all_materials(self):
        """è·å–æ‰€æœ‰ç´ æ"""
        return self.materials

    async def get_materials_by_type(self, material_type: str):
        """æ ¹æ®ç±»å‹è·å–ç´ æ"""
        return [mat for mat in self.materials if mat["type"] == material_type]

    async def search_materials(self, keyword: str):
        """æœç´¢ç´ æ"""
        keyword = keyword.lower()
        return [
            mat for mat in self.materials
            if keyword in mat["title"].lower() or
               any(keyword in tag.lower() for tag in mat["tags"])
        ]

    async def add_material(self, material_data: dict):
        """æ·»åŠ æ–°ç´ æ"""
        new_material = {
            "id": len(self.materials) + 1,
            "type": material_data.get("type"),
            "title": material_data.get("title"),
            "content": material_data.get("content"),
            "tags": material_data.get("tags", []),
            "created_at": "2025-10-07",
            "source": material_data.get("source", "user_upload"),
            "file_size": material_data.get("file_size", len(str(material_data.get("content", "")))),
            "original_url": material_data.get("original_url")
        }
        self.materials.append(new_material)
        return new_material

material_service = MaterialService()

# ==================== è´¦å·ç®¡ç†API ====================


# ==================== ç´ æç®¡ç†API ====================

# é¦–å…ˆåˆ›å»ºæ–‡ä»¶è®°å½•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
async def ensure_file_records_table():
    """ç¡®ä¿file_recordsè¡¨å­˜åœ¨"""
    import sqlite3
    from pathlib import Path

    db_path = Path("accounts.db")
    if not db_path.exists():
        return

    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS file_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    filename TEXT NOT NULL,
                    filesize REAL NOT NULL,
                    file_path TEXT NOT NULL,
                    upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            conn.commit()
            print("âœ… file_recordsè¡¨å·²ç¡®ä¿å­˜åœ¨")
    except Exception as e:
        print(f"âš ï¸ åˆ›å»ºfile_recordsè¡¨å¤±è´¥: {str(e)}")

# åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºè¡¨
def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    import asyncio
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(ensure_file_records_table())
    loop.close()

# åˆå§‹åŒ–æ•°æ®åº“
init_database()

@app.get("/api/v1/materials")
async def get_all_materials():
    """è·å–æ‰€æœ‰ç´ æ"""
    try:
        materials = await material_service.get_all_materials()
        return {
            "success": True,
            "data": {
                "materials": materials,
                "total": len(materials)
            }
        }
    except Exception as e:
        print(f"è·å–ç´ æåˆ—è¡¨å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"è·å–ç´ æåˆ—è¡¨å¤±è´¥: {str(e)}"
        }

# ==================== Social-Auto-Uploadå…¼å®¹çš„æ–‡ä»¶ç®¡ç†API ====================

@app.get("/getFiles")
async def get_all_files():
    """è·å–æ‰€æœ‰æ–‡ä»¶ - å…¼å®¹social-auto-upload"""
    try:
        import sqlite3
        from pathlib import Path

        db_path = Path("accounts.db")
        if not db_path.exists():
            return {
                "code": 200,
                "msg": "success",
                "data": []
            }

        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute("SELECT * FROM file_records ORDER BY upload_time DESC")
            rows = cursor.fetchall()

            data = [dict(row) for row in rows]

        return {
            "code": 200,
            "msg": "success",
            "data": data
        }
    except Exception as e:
        print(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
        return {
            "code": 500,
            "msg": "get file failed!",
            "data": None
        }

@app.post("/uploadSave")
async def upload_save(request: Request):
    """ä¸Šä¼ æ–‡ä»¶ - å®Œå…¨å…¼å®¹social-auto-uploadå®ç°"""
    try:
        from fastapi.responses import JSONResponse
        import uuid
        import os
        from pathlib import Path

        # è·å–è¡¨å•æ•°æ®
        form = await request.form()

        if 'file' not in form:
            return JSONResponse({
                "code": 400,
                "data": None,
                "msg": "No file part in the request"
            }, status_code=400)

        file = form['file']
        if file.filename == '':
            return JSONResponse({
                "code": 400,
                "data": None,
                "msg": "No selected file"
            }, status_code=400)

        # è·å–è¡¨å•ä¸­çš„è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰- å®Œå…¨å…¼å®¹social-auto-uploadæ ¼å¼
        custom_filename = form.get('filename', None)
        if custom_filename:
            filename = custom_filename + "." + file.filename.split('.')[-1]
        else:
            filename = file.filename

        # ç”Ÿæˆ UUID v1 - ä¸social-auto-uploadä¿æŒä¸€è‡´
        uuid_v1 = uuid.uuid1()
        print(f"UUID v1: {uuid_v1}")

        # æ„é€ æ–‡ä»¶åå’Œè·¯å¾„ - å…¼å®¹social-auto-uploadæ ¼å¼
        final_filename = f"{uuid_v1}_{filename}"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        upload_dir = Path("videoFile")
        upload_dir.mkdir(exist_ok=True)
        filepath = upload_dir / final_filename

        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'wb') as f:
            content = await file.read()
            f.write(content)

        # è®¡ç®—æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰- ç²¾ç¡®åŒ¹é…social-auto-uploadæ ¼å¼
        file_size_mb = round(float(os.path.getsize(filepath)) / (1024 * 1024), 2)

        # ä¿å­˜åˆ°æ•°æ®åº“ - å…¼å®¹social-auto-uploadæ•°æ®åº“ç»“æ„
        db_path = Path("accounts.db")
        if db_path.exists():
            import sqlite3
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO file_records (filename, filesize, file_path)
                    VALUES (?, ?, ?)
                ''', (filename, file_size_mb, final_filename))
                conn.commit()
                print("âœ… ä¸Šä¼ æ–‡ä»¶å·²è®°å½•")

        return JSONResponse({
            "code": 200,
            "msg": "File uploaded and saved successfully",
            "data": {
                "filename": filename,
                "filepath": final_filename
            }
        })

    except Exception as e:
        print(f"ä¸Šä¼ å¤±è´¥: {str(e)}")
        return JSONResponse({
            "code": 500,
            "msg": "upload failed!",
            "data": None
        }, status_code=500)

@app.get("/deleteFile")
async def delete_file(request: Request):
    """åˆ é™¤æ–‡ä»¶ - å®Œå…¨å…¼å®¹social-auto-uploadå®ç°"""
    try:
        file_id = request.query_params.get('id')

        if not file_id or not file_id.isdigit():
            return JSONResponse({
                "code": 400,
                "msg": "Invalid or missing file ID",
                "data": None
            }, status_code=400)

        import sqlite3
        from pathlib import Path

        db_path = Path("accounts.db")
        if not db_path.exists():
            return JSONResponse({
                "code": 404,
                "msg": "Database not found",
                "data": None
            }, status_code=404)

        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•
            cursor.execute("SELECT * FROM file_records WHERE id = ?", (file_id,))
            record = cursor.fetchone()

            if not record:
                return JSONResponse({
                    "code": 404,
                    "msg": "File not found",
                    "data": None
                }, status_code=404)

            record = dict(record)

            # åˆ é™¤æ•°æ®åº“è®°å½• - ä¼˜å…ˆåˆ é™¤æ•°æ®åº“è®°å½•ï¼Œä¸social-auto-uploadä¿æŒä¸€è‡´
            cursor.execute("DELETE FROM file_records WHERE id = ?", (file_id,))
            conn.commit()
            print(f"âœ… æ•°æ®åº“è®°å½•å·²åˆ é™¤: ID {file_id}")

            # å¯é€‰ï¼šåˆ é™¤ç‰©ç†æ–‡ä»¶ï¼ˆsocial-auto-uploadä¸­æœªå®ç°ï¼Œä½†æˆ‘ä»¬å¯ä»¥ä¿ç•™ï¼‰
            file_path = Path("videoFile") / record['file_path']
            if file_path.exists():
                file_path.unlink()
                print(f"âœ… ç‰©ç†æ–‡ä»¶å·²åˆ é™¤: {file_path}")

        return JSONResponse({
            "code": 200,
            "msg": "File deleted successfully",
            "data": {
                "id": record['id'],
                "filename": record['filename']
            }
        })

    except Exception as e:
        print(f"åˆ é™¤å¤±è´¥: {str(e)}")
        return JSONResponse({
            "code": 500,
            "msg": "delete failed!",
            "data": None
        }, status_code=500)

@app.get("/getFile")
async def get_file(request: Request):
    """è·å–æ–‡ä»¶ - å…¼å®¹social-auto-upload"""
    try:
        file_id = request.query_params.get('id')
        filename = request.query_params.get('filename')

        if not file_id or not file_id.isdigit():
            return JSONResponse({"error": "file id is required and must be numeric"}, status_code=400)

        # ä»æ•°æ®åº“æŸ¥è¯¢æ–‡ä»¶è·¯å¾„
        import sqlite3
        from pathlib import Path

        db_path = Path("accounts.db")
        if not db_path.exists():
            return JSONResponse({"error": "Database not found"}, status_code=404)

        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT file_path, filename FROM file_records WHERE id = ?", (int(file_id),))
            record = cursor.fetchone()

        if not record:
            return JSONResponse({"error": "File record not found"}, status_code=404)

        file_path_in_db, original_filename = record

        # é˜²æ­¢è·¯å¾„ç©¿è¶Šæ”»å‡»
        if '..' in file_path_in_db or file_path_in_db.startswith('/'):
            return JSONResponse({"error": "Invalid file path"}, status_code=400)

        from fastapi.responses import FileResponse

        file_path = Path("videoFile") / file_path_in_db

        if not file_path.exists():
            return JSONResponse({"error": "Physical file not found"}, status_code=404)

        return FileResponse(file_path, filename=original_filename)

    except Exception as e:
        print(f"è·å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return JSONResponse({"error": str(e)}, status_code=500)

# ==================== å¢å¼ºçš„ç´ æç®¡ç†API - å…¼å®¹social-auto-upload ====================

@app.delete("/api/v1/files/batch")
async def batch_delete_files(request: dict):
    """æ‰¹é‡åˆ é™¤æ–‡ä»¶ - å¢å¼ºåŠŸèƒ½"""
    try:
        file_ids = request.get("file_ids", [])

        if not file_ids:
            return JSONResponse({
                "code": 400,
                "msg": "No file IDs provided",
                "data": None
            }, status_code=400)

        import sqlite3
        from pathlib import Path

        db_path = Path("accounts.db")
        if not db_path.exists():
            return JSONResponse({
                "code": 404,
                "msg": "Database not found",
                "data": None
            }, status_code=404)

        deleted_files = []
        failed_files = []

        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            for file_id in file_ids:
                try:
                    # æŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•
                    cursor.execute("SELECT * FROM file_records WHERE id = ?", (file_id,))
                    record = cursor.fetchone()

                    if record:
                        record = dict(record)

                        # åˆ é™¤æ•°æ®åº“è®°å½•
                        cursor.execute("DELETE FROM file_records WHERE id = ?", (file_id,))

                        # åˆ é™¤ç‰©ç†æ–‡ä»¶
                        file_path = Path("videoFile") / record['file_path']
                        if file_path.exists():
                            file_path.unlink()

                        deleted_files.append({
                            "id": record['id'],
                            "filename": record['filename']
                        })
                    else:
                        failed_files.append({
                            "id": file_id,
                            "reason": "File not found"
                        })
                except Exception as e:
                    failed_files.append({
                        "id": file_id,
                        "reason": str(e)
                    })

            conn.commit()

        return JSONResponse({
            "code": 200,
            "msg": f"Batch delete completed. Success: {len(deleted_files)}, Failed: {len(failed_files)}",
            "data": {
                "deleted_files": deleted_files,
                "failed_files": failed_files,
                "total_deleted": len(deleted_files),
                "total_failed": len(failed_files)
            }
        })

    except Exception as e:
        print(f"æ‰¹é‡åˆ é™¤å¤±è´¥: {str(e)}")
        return JSONResponse({
            "code": 500,
            "msg": "Batch delete failed!",
            "data": None
        }, status_code=500)

@app.get("/api/v1/files/stats")
async def get_file_stats():
    """è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯ - å¢å¼ºåŠŸèƒ½"""
    try:
        import sqlite3
        from pathlib import Path

        db_path = Path("accounts.db")
        if not db_path.exists():
            return JSONResponse({
                "code": 200,
                "msg": "success",
                "data": {
                    "total_files": 0,
                    "total_size_mb": 0,
                    "file_types": {},
                    "recent_uploads": []
                }
            })

        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()

            # è·å–åŸºæœ¬ç»Ÿè®¡
            cursor.execute("SELECT COUNT(*), SUM(filesize) FROM file_records")
            total_count, total_size = cursor.fetchone()
            total_size = total_size or 0

            # è·å–æ–‡ä»¶ç±»å‹ç»Ÿè®¡
            cursor.execute("""
                SELECT
                    CASE
                        WHEN filename LIKE '%.mp4' THEN 'video'
                        WHEN filename LIKE '%.mov' THEN 'video'
                        WHEN filename LIKE '%.avi' THEN 'video'
                        WHEN filename LIKE '%.mkv' THEN 'video'
                        WHEN filename LIKE '%.jpg' THEN 'image'
                        WHEN filename LIKE '%.jpeg' THEN 'image'
                        WHEN filename LIKE '%.png' THEN 'image'
                        WHEN filename LIKE '%.gif' THEN 'image'
                        WHEN filename LIKE '%.mp3' THEN 'audio'
                        WHEN filename LIKE '%.wav' THEN 'audio'
                        ELSE 'other'
                    END as file_type,
                    COUNT(*) as count,
                    SUM(filesize) as total_size
                FROM file_records
                GROUP BY file_type
            """)

            file_types = {}
            for file_type, count, size in cursor.fetchall():
                file_types[file_type] = {
                    "count": count,
                    "total_size_mb": round(size or 0, 2)
                }

            # è·å–æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶
            cursor.execute("""
                SELECT id, filename, filesize, upload_time
                FROM file_records
                ORDER BY upload_time DESC
                LIMIT 10
            """)

            recent_uploads = []
            for row in cursor.fetchall():
                recent_uploads.append({
                    "id": row[0],
                    "filename": row[1],
                    "filesize_mb": round(row[2], 2),
                    "upload_time": row[3]
                })

        return JSONResponse({
            "code": 200,
            "msg": "success",
            "data": {
                "total_files": total_count,
                "total_size_mb": round(total_size, 2),
                "file_types": file_types,
                "recent_uploads": recent_uploads
            }
        })

    except Exception as e:
        print(f"è·å–æ–‡ä»¶ç»Ÿè®¡å¤±è´¥: {str(e)}")
        return JSONResponse({
            "code": 500,
            "msg": "Failed to get file stats",
            "data": None
        }, status_code=500)

@app.get("/api/v1/files/search")
async def search_files(keyword: str = "", file_type: str = "", min_size: float = 0, max_size: float = None):
    """é«˜çº§æ–‡ä»¶æœç´¢ - å¢å¼ºåŠŸèƒ½"""
    try:
        import sqlite3
        from pathlib import Path

        db_path = Path("accounts.db")
        if not db_path.exists():
            return JSONResponse({
                "code": 200,
                "msg": "success",
                "data": []
            })

        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = []
            params = []

            if keyword:
                conditions.append("(filename LIKE ? OR file_path LIKE ?)")
                params.extend([f"%{keyword}%", f"%{keyword}%"])

            if file_type:
                if file_type == "video":
                    conditions.append("(filename LIKE '%.mp4' OR filename LIKE '%.mov' OR filename LIKE '%.avi' OR filename LIKE '%.mkv')")
                elif file_type == "image":
                    conditions.append("(filename LIKE '%.jpg' OR filename LIKE '%.jpeg' OR filename LIKE '%.png' OR filename LIKE '%.gif')")
                elif file_type == "audio":
                    conditions.append("(filename LIKE '%.mp3' OR filename LIKE '%.wav')")

            if min_size > 0:
                conditions.append("filesize >= ?")
                params.append(min_size)

            if max_size is not None:
                conditions.append("filesize <= ?")
                params.append(max_size)

            # æ„å»ºå®Œæ•´æŸ¥è¯¢
            query = "SELECT * FROM file_records"
            if conditions:
                query += " WHERE " + " AND ".join(conditions)
            query += " ORDER BY upload_time DESC"

            cursor.execute(query, params)
            rows = cursor.fetchall()
            data = [dict(row) for row in rows]

        return JSONResponse({
            "code": 200,
            "msg": "success",
            "data": data
        })

    except Exception as e:
        print(f"æ–‡ä»¶æœç´¢å¤±è´¥: {str(e)}")
        return JSONResponse({
            "code": 500,
            "msg": "Search failed",
            "data": None
        }, status_code=500)

@app.get("/download/{file_path:path}")
async def download_file(file_path: str):
    """ä¸‹è½½æ–‡ä»¶ - å…¼å®¹social-auto-upload"""
    try:
        from fastapi.responses import FileResponse
        from pathlib import Path

        # é˜²æ­¢è·¯å¾„ç©¿è¶Šæ”»å‡»
        if '..' in file_path or file_path.startswith('/'):
            return JSONResponse({"error": "Invalid file path"}, status_code=400)

        full_path = Path("videoFile") / file_path

        if not full_path.exists():
            return JSONResponse({"error": "File not found"}, status_code=404)

        return FileResponse(full_path, filename=file_path)

    except Exception as e:
        print(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")
        return JSONResponse({"error": str(e)}, status_code=500)

@app.get("/api/v1/materials/search")
async def search_materials(keyword: str = ""):
    """æœç´¢ç´ æ"""
    try:
        if not keyword:
            materials = await material_service.get_all_materials()
        else:
            materials = await material_service.search_materials(keyword)

        return {
            "success": True,
            "data": {
                "materials": materials,
                "total": len(materials),
                "keyword": keyword
            }
        }
    except Exception as e:
        print(f"æœç´¢ç´ æå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"æœç´¢ç´ æå¤±è´¥: {str(e)}"
        }

@app.post("/api/v1/materials")
async def add_material(request: dict):
    """æ·»åŠ æ–°ç´ æ"""
    try:
        required_fields = ["type", "title", "content"]
        for field in required_fields:
            if not request.get(field):
                return {
                    "success": False,
                    "message": f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}"
                }

        new_material = await material_service.add_material(request)
        return {
            "success": True,
            "message": "ç´ ææ·»åŠ æˆåŠŸ",
            "data": {
                "material": new_material
            }
        }
    except Exception as e:
        print(f"æ·»åŠ ç´ æå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"æ·»åŠ ç´ æå¤±è´¥: {str(e)}"
        }

# ==================== ç¤¾äº¤å‘å¸ƒAPI - å…¼å®¹Social-Auto-Upload ====================

@app.post("/postVideo")
async def post_video(request: Request, background_tasks: BackgroundTasks):
    """å‘å¸ƒè§†é¢‘åˆ°ç¤¾äº¤å¹³å° - å®Œå…¨å…¼å®¹social-auto-uploadå®ç°"""
    try:
        import json

        # è·å–è¯·æ±‚æ•°æ® - ä¸social-auto-uploadä¿æŒä¸€è‡´
        data = await request.json()
        print(f"æ”¶åˆ°è§†é¢‘å‘å¸ƒè¯·æ±‚: {json.dumps(data, ensure_ascii=False, indent=2)}")

        # ä»JSONæ•°æ®ä¸­æå–å‚æ•° - ç²¾ç¡®åŒ¹é…social-auto-uploadæ ¼å¼
        file_list = data.get('fileList', [])
        account_list = data.get('accountList', [])
        type = data.get('type')
        platform_name = get_platform_name(type)  # æ·»åŠ å¹³å°åç§°
        title = data.get('title')
        tags = data.get('tags')  # æ³¨æ„ï¼šsocial-auto-uploadä¸­tagsä¸æ˜¯æ•°ç»„
        category = data.get('category')
        enableTimer = data.get('enableTimer')

        # é‡å¤å‘å¸ƒæ£€æµ‹ - æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶æ˜¯å¦æ­£åœ¨å‘å¸ƒä¸­
        for file_name in file_list:
            # æ„å»ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
            file_path = str((Path(__file__).parent / "videoFile" / file_name).resolve())

            if file_path in publishing_videos:
                existing_task_id = publishing_videos[file_path]
                print(f"âš ï¸ æ–‡ä»¶æ­£åœ¨å‘å¸ƒä¸­ï¼Œæ‹’ç»é‡å¤è¯·æ±‚: {file_name}")
                print(f"   å·²å­˜åœ¨ä»»åŠ¡ID: {existing_task_id}")
                return {
                    "code": 409,
                    "msg": f"æ–‡ä»¶ {file_name} æ­£åœ¨å‘å¸ƒä¸­ï¼Œè¯·å‹¿é‡å¤æäº¤ã€‚ä»»åŠ¡ID: {existing_task_id}",
                    "data": None
                }

            # æ ‡è®°è¯¥æ–‡ä»¶æ­£åœ¨å‘å¸ƒ
            task_id = str(uuid.uuid4())
            publishing_videos[file_path] = task_id
            print(f"ğŸ“ æ ‡è®°æ–‡ä»¶æ­£åœ¨å‘å¸ƒ: {file_name} -> {task_id}")
        if category == 0:
            category = None

        videos_per_day = data.get('videosPerDay')
        daily_times = data.get('dailyTimes')
        start_days = data.get('startDays')

        # æ‰“å°è·å–åˆ°çš„æ•°æ®ï¼ˆä¸social-auto-uploadæ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        print("File List:", file_list)
        print("Account List:", account_list)

        # éªŒè¯å¿…å¡«å‚æ•°
        if not title:
            return {
                "code": 400,
                "msg": "å‘å¸ƒå¤±è´¥ï¼šæ ‡é¢˜ä¸èƒ½ä¸ºç©º",
                "data": None
            }

        if not file_list:
            return {
                "code": 400,
                "msg": "å‘å¸ƒå¤±è´¥ï¼šè¯·é€‰æ‹©è¦å‘å¸ƒçš„æ–‡ä»¶",
                "data": None
            }

        if not account_list:
            return {
                "code": 400,
                "msg": "å‘å¸ƒå¤±è´¥ï¼šè¯·é€‰æ‹©å‘å¸ƒè´¦å·",
                "data": None
            }

        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        existing_files = []
        missing_files = []

        for file_name in file_list:
            # æ£€æŸ¥æ˜¯å¦æ˜¯UUIDå‘½åçš„æ–‡ä»¶ï¼ˆåœ¨videoFileç›®å½•ä¸­ï¼‰
            video_file_path = Path("videoFile") / file_name
            generated_file_path = Path("generated_videos") / file_name

            if video_file_path.exists():
                existing_files.append(str(video_file_path))
            elif generated_file_path.exists():
                existing_files.append(str(generated_file_path))
            else:
                missing_files.append(file_name)

        if missing_files:
            print(f"âš ï¸ ä»¥ä¸‹æ–‡ä»¶ä¸å­˜åœ¨: {missing_files}")
            return {
                "code": 400,
                "msg": f"å‘å¸ƒå¤±è´¥ï¼šä»¥ä¸‹æ–‡ä»¶ä¸å­˜åœ¨ - {', '.join(missing_files)}",
                "data": {"missing_files": missing_files}
            }

        # éªŒè¯è´¦å·æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        valid_accounts = []
        invalid_accounts = []

        for account_file in account_list:
            # æ”¯æŒå¤šç§è´¦å·æ–‡ä»¶è·¯å¾„æ ¼å¼
            account_paths = [
                Path("../social-auto-upload/cookiesFile") / account_file,
                Path("cookies") / account_file,
                Path("cookiesFile") / account_file,
                Path("../cookiesFile") / account_file,
                Path(account_file)  # ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„
            ]

            for account_path in account_paths:
                if account_path.exists():
                    valid_accounts.append(str(account_path))
                    break
            else:
                invalid_accounts.append(account_file)

        # å‡†å¤‡ä¼ é€’ç»™social-auto-uploadçš„è´¦å·æ–‡ä»¶åï¼ˆä¸åŒ…å«è·¯å¾„å‰ç¼€ï¼‰
        sau_account_files = []
        for valid_account_path in valid_accounts:
            path_obj = Path(valid_account_path)
            sau_account_files.append(path_obj.name)  # åªä¼ é€’æ–‡ä»¶åï¼Œsocial-auto-uploadä¼šè‡ªåŠ¨æ·»åŠ cookiesFileå‰ç¼€

        if invalid_accounts:
            print(f"âš ï¸ ä»¥ä¸‹è´¦å·æ–‡ä»¶ä¸å­˜åœ¨: {invalid_accounts}")
            return {
                "code": 400,
                "msg": f"å‘å¸ƒå¤±è´¥ï¼šä»¥ä¸‹è´¦å·æ–‡ä»¶ä¸å­˜åœ¨ - {', '.join(invalid_accounts)}",
                "data": {"invalid_accounts": invalid_accounts}
            }

        # å‡†å¤‡å‘å¸ƒä»»åŠ¡ä¿¡æ¯
        publish_task = {
            "platform": platform_name,
            "platform_type": type,
            "title": title,
            "tags": tags,
            "files": existing_files,
            "accounts": valid_accounts,
            "sau_account_files": sau_account_files,  # social-auto-uploadæ ¼å¼çš„è´¦å·æ–‡ä»¶å
            "category": category,
            "enable_timer": enableTimer,
            "videos_per_day": videos_per_day,
            "daily_times": daily_times,
            "start_days": start_days,
            "status": "prepared",
            "created_at": str(Path().resolve())
        }

        print(f"âœ… å‘å¸ƒä»»åŠ¡å‡†å¤‡å®Œæˆ:")
        print(f"  - å¹³å°: {platform_name} (ç±»å‹: {type})")
        print(f"  - æ ‡é¢˜: {title}")
        print(f"  - æ–‡ä»¶æ•°é‡: {len(existing_files)}")
        print(f"  - è´¦å·æ•°é‡: {len(valid_accounts)}")
        print(f"  - æ–‡ä»¶è·¯å¾„: {existing_files}")
        print(f"  - è´¦å·è·¯å¾„: {valid_accounts}")

        # è°ƒç”¨å®é™…çš„social-auto-uploadå‘å¸ƒåŠŸèƒ½
        try:
            import sys
            import os

            current_dir = Path(__file__).parent
            sau_path = current_dir.parent / "social-auto-upload"

            if sau_path.exists():
                # è®¾ç½®å·¥ä½œç›®å½•å’Œè·¯å¾„
                original_cwd = os.getcwd()
                os.chdir(sau_path)

                sys.path.insert(0, str(sau_path))
                sys.path.insert(0, str(sau_path / "myUtils"))
                sys.path.insert(0, str(sau_path / "utils"))
                sys.path.insert(0, str(sau_path / "conf"))

                # è®¾ç½®ç¯å¢ƒå˜é‡
                os.environ['BASE_DIR'] = str(sau_path)

                # å°è¯•å¯¼å…¥å¹¶è°ƒç”¨å‘å¸ƒæ¨¡å—
                try:
                    # é¦–å…ˆå¯¼å…¥å¿…è¦çš„æ¨¡å—
                    from myUtils.postVideo import post_video_DouYin
                    from conf import BASE_DIR
                    from utils.constant import TencentZoneTypes

                    print(f"ğŸš€ å¼€å§‹è°ƒç”¨ {platform_name} å®é™…å‘å¸ƒåŠŸèƒ½...")
                    print(f"  - å·¥ä½œç›®å½•: {os.getcwd()}")
                    print(f"  - BASE_DIR: {BASE_DIR}")
                    print(f"  - æ–‡ä»¶åˆ—è¡¨: {file_list}")
                    print(f"  - è´¦å·æ–‡ä»¶: {sau_account_files}")

                    # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå‘å¸ƒï¼Œé¿å…é˜»å¡APIå“åº”
                    async def execute_publish():
                        try:
                            # ğŸ“ å‡†å¤‡æ–‡ä»¶ï¼šå¤åˆ¶cookieæ–‡ä»¶å’Œè§†é¢‘æ–‡ä»¶åˆ°social-auto-uploadç›®å½•
                            print("ğŸ“ å‡†å¤‡å‘å¸ƒæ–‡ä»¶...")

                            # ä½¿ç”¨ç»å¯¹è·¯å¾„å¤åˆ¶æ–‡ä»¶ï¼ˆåœ¨åˆ‡æ¢ç›®å½•ä¹‹å‰ï¼‰
                            import shutil
                            media_platform_path = Path(__file__).parent

                            # 1. å¤åˆ¶cookieæ–‡ä»¶åˆ°cookiesFileç›®å½•
                            cookiesfile_dir = sau_path / "cookiesFile"
                            cookiesfile_dir.mkdir(exist_ok=True)

                            for cookie_src in valid_accounts:
                                # æºæ–‡ä»¶åœ¨ai-media-platformç›®å½•
                                cookie_src_path = media_platform_path / cookie_src
                                cookie_dst_path = cookiesfile_dir / cookie_src_path.name
                                try:
                                    shutil.copy2(cookie_src_path, cookie_dst_path)
                                    print(f"âœ… Cookieæ–‡ä»¶å·²å¤åˆ¶: {cookie_src_path.name} -> cookiesFile/")
                                except Exception as copy_error:
                                    print(f"âŒ Cookieæ–‡ä»¶å¤åˆ¶å¤±è´¥: {cookie_src_path.name} - {copy_error}")

                            # 2. å¤åˆ¶è§†é¢‘æ–‡ä»¶åˆ°videoFileç›®å½•
                            video_dir = sau_path / "videoFile"
                            video_dir.mkdir(exist_ok=True)

                            sau_video_files = []  # social-auto-uploadæ ¼å¼çš„è§†é¢‘æ–‡ä»¶å
                            for video_src in existing_files:
                                # æºæ–‡ä»¶åœ¨ai-media-platformç›®å½•
                                video_src_path = media_platform_path / video_src
                                video_dst_path = video_dir / video_src_path.name
                                try:
                                    shutil.copy2(video_src_path, video_dst_path)
                                    sau_video_files.append(video_src_path.name)
                                    print(f"âœ… è§†é¢‘æ–‡ä»¶å·²å¤åˆ¶: {video_src_path.name} -> videoFile/")
                                except Exception as copy_error:
                                    print(f"âŒ è§†é¢‘æ–‡ä»¶å¤åˆ¶å¤±è´¥: {video_src_path.name} - {copy_error}")

                            print(f"ğŸ“ æ–‡ä»¶å‡†å¤‡å®Œæˆ: {len(sau_account_files)}ä¸ªcookieæ–‡ä»¶, {len(sau_video_files)}ä¸ªè§†é¢‘æ–‡ä»¶")

                            # åˆ‡æ¢åˆ°social-auto-uploadç›®å½•æ‰§è¡Œ
                            os.chdir(sau_path)

                            if type == 3:  # æŠ–éŸ³
                                print(f"ğŸ¬ è°ƒç”¨æŠ–éŸ³å‘å¸ƒåŠŸèƒ½...")
                                # ä½¿ç”¨å…¨å±€å¯¼å…¥çš„GitHubä¼˜åŒ–ç‰ˆDouYinVideoç±»
                                if SOCIAL_AUTO_UPLOAD_AVAILABLE:
                                    print("âœ… ä½¿ç”¨GitHubä¼˜åŒ–ç‰ˆDouYinVideoç±»")
                                else:
                                    print("âŒ DouYinVideoç±»æœªå¯ç”¨")
                                    raise Exception("DouYinVideoç±»æœªå¯¼å…¥")

                                for video_file in sau_video_files:
                                    try:
                                            print(f"å¼€å§‹å‘å¸ƒè§†é¢‘: {video_file}")
                                            from datetime import datetime
                                            # æ„å»ºå®Œæ•´çš„cookieæ–‡ä»¶è·¯å¾„
                                            account_file_path = None
                                            if sau_account_files:
                                                account_file_path = f"cookiesFile/{sau_account_files[0]}"

                                            # æ„å»ºå®Œæ•´çš„è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ŒåŒ¹é…social-auto-uploadæ ¼å¼
                                            video_file_path = str(Path(BASE_DIR) / "videoFile" / video_file)

                                                    # æ ¹æ®enableTimerè®¾ç½®æ­£ç¡®çš„å‘å¸ƒæ—¶é—´
                                            publish_date = None
                                            if enableTimer and enableTimer == 1:
                                                # ä½¿ç”¨å®šæ—¶å‘å¸ƒï¼Œè®¡ç®—å‘å¸ƒæ—¶é—´
                                                from utils.files_times import generate_schedule_time_next_day
                                                publish_datetimes = generate_schedule_time_next_day(
                                                    len(sau_video_files), videos_per_day, daily_times, start_days
                                                )
                                                publish_date = publish_datetimes[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„å‘å¸ƒæ—¶é—´
                                                print(f"ğŸ“… ä½¿ç”¨å®šæ—¶å‘å¸ƒæ—¶é—´: {publish_date}")
                                            else:
                                                # ç«‹å³å‘å¸ƒï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                                                publish_date = datetime.now()
                                                print(f"ğŸš€ ä½¿ç”¨ç«‹å³å‘å¸ƒæ¨¡å¼")

                                            douyin_uploader = DouYinVideo(
                                                title=title,
                                                file_path=video_file_path,
                                                tags=tags,
                                                publish_date=publish_date,
                                                account_file=account_file_path
                                            )
                                            await asyncio.get_event_loop().run_in_executor(
                                                None, lambda: asyncio.run(douyin_uploader.main())
                                            )
                                            print(f"âœ… è§†é¢‘å‘å¸ƒæˆåŠŸ: {video_file}")
                                    except Exception as video_error:
                                        print(f"âŒ è§†é¢‘å‘å¸ƒå¤±è´¥: {video_file} - {str(video_error)}")
                                        raise video_error
                                print(f"âœ… {platform_name} å‘å¸ƒæ‰§è¡Œå®Œæˆ")
                        except Exception as publish_error:
                            print(f"âŒ {platform_name} å‘å¸ƒæ‰§è¡Œå¤±è´¥: {str(publish_error)}")
                            import traceback
                            traceback.print_exc()
                        finally:
                            # æ¢å¤åŸå·¥ä½œç›®å½•
                            os.chdir(original_cwd)

                    # å¯åŠ¨åå°å‘å¸ƒä»»åŠ¡
                    background_tasks.add_task(execute_publish)

                    # æ¢å¤åŸå·¥ä½œç›®å½•
                    os.chdir(original_cwd)

                    # ä½¿ç”¨social-auto-uploadæ ‡å‡†å“åº”æ ¼å¼
                    return {
                        "code": 200,
                        "msg": None,
                        "data": None
                    }

                except ImportError as import_error:
                    print(f"âš ï¸ æ— æ³•å¯¼å…¥social-auto-uploadå‘å¸ƒæ¨¡å—: {str(import_error)}")
                    import traceback
                    traceback.print_exc()
                    # æ¢å¤åŸå·¥ä½œç›®å½•
                    os.chdir(original_cwd)
                    # ç»§ç»­æ‰§è¡Œå¢å¼ºæ¨¡æ‹Ÿå‘å¸ƒ

        except Exception as setup_error:
            print(f"âš ï¸ social-auto-uploadç¯å¢ƒè®¾ç½®å¤±è´¥: {str(setup_error)}")
            import traceback
            traceback.print_exc()
            try:
                os.chdir(original_cwd)
            except:
                pass

        # å¢å¼ºæ¨¡æ‹Ÿå‘å¸ƒ - æä¾›æ›´å¤šæœ‰ç”¨çš„ä¿¡æ¯
        print(f"ğŸ”„ æ‰§è¡Œå¢å¼ºæ¨¡æ‹Ÿå‘å¸ƒ...")

        # æ¨¡æ‹Ÿå‘å¸ƒè¿›åº¦
        total_tasks = len(existing_files) * len(valid_accounts)
        print(f"ğŸ“Š è®¡åˆ’æ‰§è¡Œ {total_tasks} ä¸ªå‘å¸ƒä»»åŠ¡")

        # æ¨¡æ‹Ÿå‘å¸ƒæ—¶é—´ï¼ˆæ ¹æ®æ–‡ä»¶å¤§å°å’Œæ•°é‡ï¼‰
        import time
        base_delay = 2  # åŸºç¡€å»¶è¿Ÿ2ç§’
        file_delay = len(existing_files) * 0.5  # æ¯ä¸ªæ–‡ä»¶å¢åŠ 0.5ç§’
        account_delay = len(valid_accounts) * 0.3  # æ¯ä¸ªè´¦å·å¢åŠ 0.3ç§’
        total_delay = base_delay + file_delay + account_delay

        print(f"â±ï¸ é¢„è®¡å‘å¸ƒæ—¶é—´: {total_delay:.1f} ç§’")
        await asyncio.sleep(min(total_delay, 5))  # æœ€å¤šç­‰å¾…5ç§’

        # ç”Ÿæˆè¯¦ç»†çš„å‘å¸ƒæŠ¥å‘Š
        publish_report = {
            "platform": platform_name,
            "platform_type": type,
            "title": title,
            "tags": tags,
            "files": existing_files,
            "accounts": valid_accounts,
            "status": "completed",
            "published_files": len(existing_files),
            "used_accounts": len(valid_accounts),
            "publish_time": f"{total_delay:.1f}s",
            "publish_method": "enhanced_simulation",
            "message": f"å·²å‡†å¤‡ {len(existing_files)} ä¸ªæ–‡ä»¶å‘å¸ƒåˆ° {len(valid_accounts)} ä¸ª{platform_name}è´¦å·",
            "next_steps": [
                "è¦å¯ç”¨å®é™…å‘å¸ƒï¼Œè¯·ç¡®ä¿social-auto-uploadç¯å¢ƒé…ç½®æ­£ç¡®",
                "æ£€æŸ¥è´¦å·Cookieæ–‡ä»¶æœ‰æ•ˆæ€§",
                "ç¡®è®¤è§†é¢‘æ–‡ä»¶æ ¼å¼ç¬¦åˆå¹³å°è¦æ±‚"
            ]
        }

        print(f"âœ… {platform_name} æ¨¡æ‹Ÿå‘å¸ƒå®Œæˆ")
        print(f"ğŸ“‹ å‘å¸ƒæŠ¥å‘Š: {publish_report}")

        # ä½¿ç”¨social-auto-uploadæ ‡å‡†å“åº”æ ¼å¼
        result = {
            "code": 200,
            "msg": None,
            "data": None
        }

        # æ¸…ç†é‡å¤å‘å¸ƒæ£€æµ‹è®°å½•ï¼ˆæˆåŠŸæƒ…å†µï¼‰
        for file_name in file_list:
            file_path = str((Path(__file__).parent / "videoFile" / file_name).resolve())
            if file_path in publishing_videos:
                del publishing_videos[file_path]
                print(f"âœ… å·²æ¸…ç†å‘å¸ƒæ£€æµ‹è®°å½•: {file_name}")

        return result

    except Exception as e:
        print(f"âŒ å‘å¸ƒAPIè°ƒç”¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

        return {
            "code": 500,
            "msg": f"å‘å¸ƒå¤±è´¥: {str(e)}",
            "data": None
        }
    finally:
        # æ¸…ç†é‡å¤å‘å¸ƒæ£€æµ‹è®°å½•
        for file_name in file_list:
            # ä½¿ç”¨å…¨å±€Pathå˜é‡ï¼Œé¿å…å±€éƒ¨å¯¼å…¥å†²çª
            file_path = str((Path(__file__).parent / "videoFile" / file_name).resolve())
            if file_path in publishing_videos:
                del publishing_videos[file_path]
                print(f"âœ… å·²æ¸…ç†å‘å¸ƒæ£€æµ‹è®°å½•: {file_name}")

@app.post("/postVideoBatch")
async def post_video_batch(request: Request):
    """æ‰¹é‡å‘å¸ƒè§†é¢‘ - å…¼å®¹social-auto-upload"""
    try:
        import json

        # è·å–è¯·æ±‚æ•°æ®
        data = await request.json()
        print(f"æ”¶åˆ°æ‰¹é‡è§†é¢‘å‘å¸ƒè¯·æ±‚: {json.dumps(data, ensure_ascii=False, indent=2)}")

        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥è°ƒç”¨å•ä¸ªå‘å¸ƒ
        # å®é™…å®ç°ä¸­åº”è¯¥æ”¯æŒçœŸæ­£çš„æ‰¹é‡å¤„ç†
        results = []

        # æ¨¡æ‹Ÿæ‰¹é‡å‘å¸ƒå¤„ç†
        for i, item in enumerate(data.get('items', [])):
            print(f"å¤„ç†ç¬¬ {i+1} ä¸ªå‘å¸ƒä»»åŠ¡")

            # è°ƒç”¨å•ä¸ªå‘å¸ƒ
            result = await post_video_item(item)
            results.append(result)

            # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡å¿«è¯·æ±‚
            await asyncio.sleep(0.5)

        return {
            "code": 200,
            "msg": "æ‰¹é‡å‘å¸ƒä»»åŠ¡å·²å¯åŠ¨",
            "data": {
                "total": len(results),
                "results": results
            }
        }

    except Exception as e:
        print(f"âŒ æ‰¹é‡å‘å¸ƒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

        return {
            "code": 500,
            "msg": f"æ‰¹é‡å‘å¸ƒå¤±è´¥: {str(e)}",
            "data": None
        }

async def post_video_item(publish_data):
    """å•ä¸ªè§†é¢‘å‘å¸ƒé¡¹å¤„ç†"""
    try:
        # å¤åˆ¶postVideoçš„æ ¸å¿ƒé€»è¾‘
        file_list = publish_data.get('fileList', [])
        account_list = publish_data.get('accountList', [])
        type = publish_data.get('type')
        title = publish_data.get('title')
        tags = publish_data.get('tags', [])

        platform_names = {1: "å°çº¢ä¹¦", 2: "è§†é¢‘å·", 3: "æŠ–éŸ³", 4: "å¿«æ‰‹"}
        platform_name = platform_names.get(type, f"å¹³å°{type}")

        # æ¨¡æ‹Ÿå‘å¸ƒ
        await asyncio.sleep(0.5)

        return {
            "platform": platform_name,
            "status": "published",
            "title": title,
            "files_count": len(file_list),
            "accounts_count": len(account_list)
        }

    except Exception as e:
        return {
            "platform": f"å¹³å°{publish_data.get('type', 'unknown')}",
            "status": "failed",
            "error": str(e)
        }

# ==================== è§†é¢‘çŠ¶æ€æ£€æŸ¥ ====================

@app.get("/api/v1/video/status/{task_id}")
async def get_video_status(task_id: str):
    """è·å–è§†é¢‘ç”Ÿæˆä»»åŠ¡çŠ¶æ€"""
    try:
        print(f"æ”¶åˆ°è§†é¢‘çŠ¶æ€æŸ¥è¯¢è¯·æ±‚: task_id={task_id}")

        # è°ƒç”¨ComfyUI APIåŒ…è£…å™¨æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        comfyui_api_url = "http://192.168.1.246:5001"

        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{comfyui_api_url}/api/task_status/{task_id}",
                timeout=aiohttp.ClientTimeout(total=10)
            ) as response:

                if response.status == 200:
                    result = await response.json()
                    print(f"ComfyUI APIåŒ…è£…å™¨çŠ¶æ€æŸ¥è¯¢æˆåŠŸ: {result}")

                    # è§£æå¹¶è¿”å›çŠ¶æ€ä¿¡æ¯
                    status = result.get("status", "unknown")
                    message = result.get("message", "")

                    if status == "completed":
                        return {
                            "success": True,
                            "status": "completed",
                            "message": "è§†é¢‘ç”Ÿæˆå®Œæˆ",
                            "data": result.get("data", {})
                        }
                    elif status == "failed":
                        return {
                            "success": False,
                            "status": "failed",
                            "message": f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {message}",
                            "error": result.get("error", "unknown error")
                        }
                    elif status in ["submitted", "processing", "pending"]:
                        return {
                            "success": True,
                            "status": status,
                            "message": f"ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­: {message}" if message else f"ä»»åŠ¡çŠ¶æ€: {status}"
                        }
                    else:
                        return {
                            "success": True,
                            "status": status,
                            "message": f"æœªçŸ¥çŠ¶æ€: {status}"
                        }

                elif response.status == 404:
                    return {
                        "success": False,
                        "status": "not_found",
                        "message": f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"
                    }
                else:
                    error_text = await response.text()
                    print(f"ComfyUI APIåŒ…è£…å™¨çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {response.status}, {error_text}")
                    return {
                        "success": False,
                        "status": "error",
                        "message": f"çŠ¶æ€æŸ¥è¯¢å¤±è´¥: HTTP {response.status}"
                    }

    except asyncio.TimeoutError:
        return {
            "success": False,
            "status": "timeout",
            "message": "çŠ¶æ€æŸ¥è¯¢è¶…æ—¶"
        }
    except Exception as e:
        print(f"è§†é¢‘çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "status": "error",
            "message": f"çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {str(e)}"
        }

# ==================== è§†é¢‘æ–‡ä»¶æœåŠ¡ ====================

@app.get("/api/v1/video/file/{filename}")
async def get_video_file(filename: str):
    """è·å–æœ¬åœ°è§†é¢‘æ–‡ä»¶"""
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åä¸åŒ…å«è·¯å¾„éå†å­—ç¬¦
        safe_filename = filename.replace("..", "").replace("/", "").replace("\\", "")
        file_path = LOCAL_VIDEO_DIR / safe_filename

        if not file_path.exists():
            return {
                "success": False,
                "message": f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {filename}"
            }

        if not file_path.suffix.lower() == '.mp4':
            return {
                "success": False,
                "message": "åªæ”¯æŒMP4æ ¼å¼çš„è§†é¢‘æ–‡ä»¶"
            }

        # è¿”å›è§†é¢‘æ–‡ä»¶
        return FileResponse(
            path=str(file_path),
            media_type="video/mp4",
            filename=safe_filename
        )

    except Exception as e:
        print(f"è·å–è§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"è·å–è§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}"
        }

# ============================================================================
# è´¦å·ç®¡ç†åŠŸèƒ½ - å…¼å®¹å‰ç«¯æ—§APIæ ¼å¼
# ============================================================================
# è´¦å·ç®¡ç†ç³»ç»Ÿ - å®Œå…¨å…¼å®¹social-auto-upload
# ============================================================================

import sqlite3
from pathlib import Path

# æ•°æ®åº“è·¯å¾„
ACCOUNT_DB_PATH = Path("./accounts.db")

def init_account_db():
    """åˆå§‹åŒ–è´¦å·æ•°æ®åº“"""
    conn = sqlite3.connect(ACCOUNT_DB_PATH)
    cursor = conn.cursor()

    cursor.execute('''
    CREATE TABLE IF NOT EXISTS user_info (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        type INTEGER NOT NULL,
        filePath TEXT NOT NULL,
        userName TEXT NOT NULL,
        status INTEGER DEFAULT 0
    )
    ''')

    conn.commit()
    conn.close()
    print("âœ… è´¦å·æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

def get_platform_name(type_id):
    """æ ¹æ®ç±»å‹IDè·å–å¹³å°åç§°"""
    type_map = {
        1: "å°çº¢ä¹¦",
        2: "è§†é¢‘å·",
        3: "æŠ–éŸ³",
        4: "å¿«æ‰‹"
    }
    return type_map.get(type_id, "æœªçŸ¥å¹³å°")

def get_platform_type(platform_name):
    """æ ¹æ®å¹³å°åç§°è·å–ç±»å‹ID"""
    platform_map = {
        "å°çº¢ä¹¦": 1,
        "è§†é¢‘å·": 2,
        "æŠ–éŸ³": 3,
        "å¿«æ‰‹": 4
    }
    return platform_map.get(platform_name, 1)

# ==================== æŠ–éŸ³å‘å¸ƒAPI ====================

def get_account_file(account_id: Optional[str] = None) -> str:
    """è·å–è´¦å·cookieæ–‡ä»¶è·¯å¾„"""
    if account_id:
        cookie_file = COOKIE_STORAGE / f"{account_id}.json"
        if cookie_file.exists():
            return str(cookie_file)

    # å¦‚æœæ²¡æœ‰æŒ‡å®šè´¦å·IDæˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤çš„
    default_cookies = list(COOKIE_STORAGE.glob("*.json"))
    if default_cookies:
        return str(default_cookies[0])

    # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨social-auto-uploadçš„æ ¼å¼
    douyin_cookie = COOKIE_STORAGE / "douyin_uploader" / "account.json"
    if douyin_cookie.exists():
        return str(douyin_cookie)

    raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æœ‰æ•ˆçš„æŠ–éŸ³è´¦å·cookieæ–‡ä»¶")


@app.post("/publish/douyin", response_model=PublishResponse)
async def publish_douyin(request: PublishRequest, background_tasks: BackgroundTasks):
    """
    å‘å¸ƒè§†é¢‘åˆ°æŠ–éŸ³ - ä½¿ç”¨social-auto-uploadæ–¹å¼
    """
    if not SOCIAL_AUTO_UPLOAD_AVAILABLE:
        raise HTTPException(status_code=500, detail="social-auto-uploadæ¨¡å—ä¸å¯ç”¨")

    # ç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())

    # éªŒè¯è§†é¢‘æ–‡ä»¶å­˜åœ¨
    video_path = Path(request.video_path)
    if not video_path.exists():
        raise HTTPException(status_code=404, detail=f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {request.video_path}")

    # é‡å¤å‘å¸ƒæ£€æµ‹ - é˜²æ­¢åŒä¸€è§†é¢‘é‡å¤å‘å¸ƒ
    video_path_str = str(video_path.resolve())
    if video_path_str in publishing_videos:
        existing_task_id = publishing_videos[video_path_str]
        existing_task = publish_tasks.get(existing_task_id)

        # å¦‚æœç°æœ‰ä»»åŠ¡è¿˜åœ¨è¿›è¡Œä¸­ï¼ˆpendingæˆ–uploadingçŠ¶æ€ï¼‰ï¼Œæ‹’ç»é‡å¤å‘å¸ƒ
        if existing_task and existing_task["status"] in ["pending", "uploading"]:
            raise HTTPException(
                status_code=409,
                detail=f"è¯¥è§†é¢‘æ­£åœ¨å‘å¸ƒä¸­ï¼Œè¯·å‹¿é‡å¤æäº¤ã€‚ä»»åŠ¡ID: {existing_task_id}"
            )

    # æ ‡è®°è¯¥è§†é¢‘æ­£åœ¨å‘å¸ƒ
    publishing_videos[video_path_str] = task_id

    # è·å–è´¦å·æ–‡ä»¶
    try:
        account_file = get_account_file(request.account_id or request.account_file)
    except HTTPException:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æœ‰æ•ˆçš„æŠ–éŸ³è´¦å·ï¼Œè¯·å…ˆæ·»åŠ è´¦å·")

    # è§£æå‘å¸ƒæ—¶é—´
    publish_time = None
    if request.publish_time:
        try:
            publish_time = datetime.fromisoformat(request.publish_time.replace('Z', '+00:00'))
        except ValueError:
            raise HTTPException(status_code=400, detail="å‘å¸ƒæ—¶é—´æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ISOæ ¼å¼")

    # åˆ›å»ºä»»åŠ¡
    task_info = {
        "task_id": task_id,
        "status": "pending",
        "title": request.title,
        "video_path": str(video_path),
        "tags": request.tags,
        "account_file": account_file,
        "publish_time": publish_time,
        "created_at": datetime.now(),
        "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…æ‰§è¡Œ"
    }

    publish_tasks[task_id] = task_info

    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(execute_douyin_publish, task_id)

    return PublishResponse(
        task_id=task_id,
        status="pending",
        message="å‘å¸ƒä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨æ‰§è¡Œä¸­"
    )


@app.get("/publish/status/{task_id}")
async def get_publish_status(task_id: str):
    """è·å–å‘å¸ƒä»»åŠ¡çŠ¶æ€"""
    if task_id not in publish_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task_info = publish_tasks[task_id]
    return {
        "task_id": task_id,
        "status": task_info["status"],
        "message": task_info.get("message", ""),
        "created_at": task_info["created_at"],
        "updated_at": task_info.get("updated_at"),
        "error": task_info.get("error")
    }


@app.get("/publish/tasks")
async def list_publish_tasks():
    """åˆ—å‡ºæ‰€æœ‰å‘å¸ƒä»»åŠ¡"""
    return {
        "tasks": [
            {
                "task_id": task_id,
                "status": task_info["status"],
                "title": task_info["title"],
                "created_at": task_info["created_at"],
                "message": task_info.get("message", "")
            }
            for task_id, task_info in publish_tasks.items()
        ]
    }


@app.get("/publish/test")
async def test_publish():
    """
    æµ‹è¯•å‘å¸ƒåŠŸèƒ½ - æŸ¥çœ‹å¯ç”¨çš„è´¦å·å’Œcookie
    """
    try:
        # æ£€æŸ¥social-auto-uploadå¯ç”¨æ€§
        if not SOCIAL_AUTO_UPLOAD_AVAILABLE:
            return {
                "status": "error",
                "message": "social-auto-uploadæ¨¡å—ä¸å¯ç”¨",
                "social_root": str(SOCIAL_ROOT),
                "social_exists": SOCIAL_ROOT.exists()
            }

        # æ£€æŸ¥æ•°æ®åº“
        db_exists = DATABASE_PATH.exists()

        # æ£€æŸ¥cookieæ–‡ä»¶
        cookie_files = list(COOKIE_STORAGE.glob("*.json"))
        douyin_cookies = [f for f in cookie_files if "douyin" in f.name.lower()]

        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
        video_dir = BASE_DIR / "videos"
        video_files = list(video_dir.glob("*.mp4")) if video_dir.exists() else []

        return {
            "status": "success",
            "social_auto_upload_available": True,
            "database_exists": db_exists,
            "cookie_files_count": len(cookie_files),
            "douyin_cookie_files": [f.name for f in douyin_cookies],
            "video_files_count": len(video_files),
            "video_files": [f.name for f in video_files[:5]],  # åªæ˜¾ç¤ºå‰5ä¸ª
            "paths": {
                "base_dir": str(BASE_DIR),
                "database_path": str(DATABASE_PATH),
                "cookie_storage": str(COOKIE_STORAGE),
                "video_dir": str(video_dir)
            }
        }

    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }


async def execute_douyin_publish(task_id: str):
    """
    æ‰§è¡ŒæŠ–éŸ³å‘å¸ƒä»»åŠ¡ - ä½¿ç”¨social-auto-uploadçš„DouYinVideoç±»
    """
    task_info = publish_tasks[task_id]

    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task_info["status"] = "uploading"
        task_info["message"] = "æ­£åœ¨ä¸Šä¼ è§†é¢‘åˆ°æŠ–éŸ³..."
        task_info["updated_at"] = datetime.now()

        print(f"å¼€å§‹æ‰§è¡ŒæŠ–éŸ³å‘å¸ƒä»»åŠ¡ {task_id}: {task_info['title']}")

        # ä½¿ç”¨social-auto-uploadçš„DouYinVideoç±»
        video_obj = DouYinVideo(
            title=task_info["title"],
            file_path=task_info["video_path"],
            tags=task_info["tags"],
            publish_date=task_info.get("publish_time") or datetime.now(),
            account_file=task_info["account_file"],
            thumbnail_path=None
        )

        # æ‰§è¡Œä¸Šä¼ 
        await video_obj.main()

        # ä»»åŠ¡å®Œæˆ
        task_info["status"] = "completed"
        task_info["message"] = "è§†é¢‘å‘å¸ƒæˆåŠŸ"
        task_info["updated_at"] = datetime.now()

        print(f"æŠ–éŸ³å‘å¸ƒä»»åŠ¡ {task_id} æ‰§è¡ŒæˆåŠŸ")

        # æ¸…ç†é‡å¤å‘å¸ƒæ£€æµ‹è®°å½•
        video_path_str = task_info.get("video_path", "")
        if video_path_str and video_path_str in publishing_videos:
            del publishing_videos[video_path_str]
            print(f"âœ… å·²æ¸…ç†å‘å¸ƒæ£€æµ‹è®°å½•: {video_path_str}")

    except Exception as e:
        # ä»»åŠ¡å¤±è´¥
        task_info["status"] = "failed"
        task_info["message"] = f"å‘å¸ƒå¤±è´¥: {str(e)}"
        task_info["error"] = str(e)
        task_info["updated_at"] = datetime.now()

        print(f"æŠ–éŸ³å‘å¸ƒä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}")

        # æ¸…ç†é‡å¤å‘å¸ƒæ£€æµ‹è®°å½•ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ¸…ç†ï¼Œå…è®¸é‡æ–°å°è¯•ï¼‰
        video_path_str = task_info.get("video_path", "")
        if video_path_str and video_path_str in publishing_videos:
            del publishing_videos[video_path_str]
            print(f"âœ… å·²æ¸…ç†å‘å¸ƒæ£€æµ‹è®°å½•: {video_path_str}ï¼ˆä»»åŠ¡å¤±è´¥ï¼‰")


# åˆå§‹åŒ–æ•°æ®åº“
init_account_db()

@app.get("/getValidAccounts")
async def get_valid_accounts():
    """è·å–æœ‰æ•ˆè´¦å·åˆ—è¡¨ - å®Œå…¨å…¼å®¹social-auto-uploadå®ç°ï¼ŒåŒ…å«CookieéªŒè¯"""
    try:
        with sqlite3.connect(ACCOUNT_DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT * FROM user_info')
            rows = cursor.fetchall()

            if not rows:
                return {
                    "code": 200,
                    "msg": None,
                    "data": []
                }

            print(f"\nğŸ“‹ å¼€å§‹éªŒè¯ {len(rows)} ä¸ªè´¦å·çš„Cookieæœ‰æ•ˆæ€§...")

            # è½¬æ¢ä¸ºsocial-auto-uploadæ ¼å¼çš„æ•°ç»„åˆ—è¡¨
            accounts_for_validation = []
            for row in rows:
                accounts_for_validation.append([row[0], row[1], row[2], row[3], row[4]])

            # æ‰¹é‡éªŒè¯Cookieæœ‰æ•ˆæ€§
            try:
                updated_accounts = await batch_check_cookies(accounts_for_validation)
                print("âœ… CookieéªŒè¯å®Œæˆ")

                # æ›´æ–°æ•°æ®åº“ä¸­çš„çŠ¶æ€
                for account in updated_accounts:
                    account_id, platform_type, cookie_file, username, new_status = account
                    cursor.execute('''
                    UPDATE user_info
                    SET status = ?
                    WHERE id = ?
                    ''', (new_status, account_id))
                conn.commit()
                print("âœ… æ•°æ®åº“çŠ¶æ€æ›´æ–°å®Œæˆ")

            except Exception as cookie_error:
                print(f"âš ï¸ CookieéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹çŠ¶æ€: {str(cookie_error)}")
                # å¦‚æœCookieéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                updated_accounts = accounts_for_validation

            # è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼ï¼Œå®Œå…¨åŒ¹é…social-auto-upload
            frontend_data = []
            for account in updated_accounts:
                account_id, platform_type, cookie_file, username, status = account

                account = {
                    "id": account_id,
                    "type": platform_type,
                    "filePath": cookie_file,
                    "userName": username,
                    "status": status,
                    # å‰ç«¯å…¼å®¹å­—æ®µ
                    "name": username,  # userNameä½œä¸ºname
                    "platform": get_platform_name(platform_type),
                    "avatar": f"https://api.dicebear.com/7.x/initials/svg?seed={username}"
                }
                frontend_data.append(account)

            print(f"ğŸ“Š è¿”å› {len(frontend_data)} ä¸ªè´¦å·æ•°æ®")
            return {
                "code": 200,
                "msg": None,
                "data": frontend_data
            }
    except Exception as e:
        print(f"âŒ è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {str(e)}")
        return {
            "code": 500,
            "msg": f"è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {str(e)}",
            "data": None
        }

@app.post("/account")
async def add_account(request: dict):
    """æ·»åŠ è´¦å· - å…¼å®¹social-auto-uploadå‰ç«¯"""
    try:
        platform = request.get("platform", "")
        name = request.get("name", "")

        if not platform or not name:
            return {
                "code": 400,
                "message": "å¹³å°å’Œåç§°ä¸èƒ½ä¸ºç©º"
            }

        type_id = get_platform_type(platform)
        file_path = f"cookies/{platform.lower()}_account_{name}.json"

        with sqlite3.connect(ACCOUNT_DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO user_info (type, filePath, userName, status)
                VALUES (?, ?, ?, ?)
            ''', (type_id, file_path, name, 1))
            conn.commit()

            # è·å–æ’å…¥çš„ID
            account_id = cursor.lastrowid

        # è¿”å›å‰ç«¯æœŸæœ›çš„æ ¼å¼
        new_account = {
            "id": account_id,
            "type": type_id,
            "filePath": file_path,
            "userName": name,
            "status": 1,
            "name": name,
            "platform": platform,
            "avatar": f"https://api.dicebear.com/7.x/initials/svg?seed={name}"
        }

        return {
            "code": 200,
            "data": new_account,
            "message": "è´¦å·æ·»åŠ æˆåŠŸ"
        }
    except Exception as e:
        print(f"æ·»åŠ è´¦å·å¤±è´¥: {str(e)}")
        return {
            "code": 500,
            "message": f"æ·»åŠ è´¦å·å¤±è´¥: {str(e)}"
        }

@app.post("/updateUserinfo")
async def update_account(request: dict):
    """æ›´æ–°è´¦å·ä¿¡æ¯ - å®Œå…¨å…¼å®¹social-auto-upload"""
    try:
        user_id = request.get('id')
        type = request.get('type')
        userName = request.get('userName')

        if not user_id:
            return {
                "code": 400,
                "message": "è´¦å·IDä¸èƒ½ä¸ºç©º"
            }

        with sqlite3.connect(ACCOUNT_DB_PATH) as conn:
            cursor = conn.cursor()

            # æ„å»ºæ›´æ–°è¯­å¥
            if type and userName:
                cursor.execute('''
                    UPDATE user_info
                    SET type = ?, userName = ?
                    WHERE id = ?
                ''', (type, userName, user_id))
            elif type:
                cursor.execute('''
                    UPDATE user_info
                    SET type = ?
                    WHERE id = ?
                ''', (type, user_id))
            elif userName:
                cursor.execute('''
                    UPDATE user_info
                    SET userName = ?
                    WHERE id = ?
                ''', (userName, user_id))

            conn.commit()

            if cursor.rowcount == 0:
                return {
                    "code": 404,
                    "message": "è´¦å·ä¸å­˜åœ¨"
                }

        return {
            "code": 200,
            "message": "account update successfully",
            "data": None
        }
    except Exception as e:
        print(f"æ›´æ–°è´¦å·å¤±è´¥: {str(e)}")
        return {
            "code": 500,
            "message": f"æ›´æ–°è´¦å·å¤±è´¥: {str(e)}"
        }

@app.get("/deleteAccount")
async def delete_account(id: int = None):
    """åˆ é™¤è´¦å· - å®Œå…¨å…¼å®¹social-auto-upload"""
    try:
        if id is None:
            return {
                "code": 400,
                "msg": "Missing id parameter",
                "data": None
            }

        with sqlite3.connect(ACCOUNT_DB_PATH) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•
            cursor.execute("SELECT * FROM user_info WHERE id = ?", (id,))
            record = cursor.fetchone()

            if not record:
                return {
                    "code": 404,
                    "msg": "account not found",
                    "data": None
                }

            # åˆ é™¤æ•°æ®åº“è®°å½•
            cursor.execute("DELETE FROM user_info WHERE id = ?", (id,))
            conn.commit()

        return {
            "code": 200,
            "msg": "account deleted successfully",
            "data": None
        }
    except Exception as e:
        print(f"åˆ é™¤è´¦å·å¤±è´¥: {str(e)}")
        return {
            "code": 500,
            "msg": "delete failed!",
            "data": None
        }

# SSE ç™»å½•æ¥å£ - å…¼å®¹social-auto-upload
from fastapi.responses import StreamingResponse
import queue
import threading
import asyncio

@app.get("/login")
async def login(type: str = None, id: str = None):
    """SSEç™»å½•æ¥å£ - å®Œå…¨å…¼å®¹social-auto-uploadå®ç°ï¼Œæ”¯æŒçœŸå®Playwrightç™»å½•"""
    if not type or not id:
        return {"error": "Missing type or id parameter"}, 400

    print(f"ğŸ” æ”¶åˆ°ç™»å½•è¯·æ±‚: å¹³å°{type}, è´¦å·{id}")

    # è·å–æˆ–åˆ›å»ºçŠ¶æ€é˜Ÿåˆ—
    status_queue = login_service.get_queue(id)

    # å¯åŠ¨å¼‚æ­¥ç™»å½•ä»»åŠ¡
    task = asyncio.create_task(run_login_process(type, id, status_queue))

    async def generate():
        try:
            while True:
                if not status_queue.empty():
                    msg = status_queue.get()
                    print(f"ğŸ“¨ å‘é€SSEæ¶ˆæ¯: {msg[:50]}...")
                    yield f"data: {msg}\n\n"

                    # å¦‚æœæ˜¯ç™»å½•å®Œæˆæ¶ˆæ¯ï¼Œç»“æŸSSEè¿æ¥
                    if msg in ['200', '500']:
                        print(f"âœ… ç™»å½•æµç¨‹å®Œæˆ: {msg}")
                        break
                else:
                    await asyncio.sleep(0.1)
        except Exception as e:
            print(f"[!] SSEç”Ÿæˆå¼‚å¸¸: {str(e)}")
            yield f"data: 500\n\n"
        finally:
            # æ¸…ç†é˜Ÿåˆ—
            login_service.remove_queue(id)
            print(f"ğŸ§¹ æ¸…ç†ç™»å½•é˜Ÿåˆ—: {id}")

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
            "Connection": "keep-alive"
        }
    )

# æ¨¡æ‹Ÿç™»å½•åæ›´æ–°æ•°æ®åº“çš„æ¥å£
@app.post("/login/complete")
async def complete_login(request: dict):
    """ç™»å½•å®Œæˆåçš„å›è°ƒæ¥å£"""
    try:
        account_id = request.get('id')
        platform = request.get('platform')
        status = request.get('status')  # '200' æˆåŠŸ, '500' å¤±è´¥

        if not account_id or not platform:
            return {"code": 400, "message": "Missing required parameters"}

        # å¦‚æœç™»å½•æˆåŠŸï¼Œæ›´æ–°æˆ–åˆ›å»ºè´¦å·è®°å½•
        if status == '200':
            type_id = get_platform_type(platform)
            file_path = f"cookies/{platform.lower()}_account_{account_id}.json"

            with sqlite3.connect(ACCOUNT_DB_PATH) as conn:
                cursor = conn.cursor()
                # æ£€æŸ¥è´¦å·æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("SELECT id FROM user_info WHERE userName = ?", (account_id,))
                existing = cursor.fetchone()

                if existing:
                    # æ›´æ–°çŠ¶æ€ä¸ºæœ‰æ•ˆ
                    cursor.execute("UPDATE user_info SET status = 1 WHERE userName = ?", (account_id,))
                else:
                    # åˆ›å»ºæ–°è´¦å·
                    cursor.execute('''
                        INSERT INTO user_info (type, filePath, userName, status)
                        VALUES (?, ?, ?, ?)
                    ''', (type_id, file_path, account_id, 1))

                conn.commit()

        # é€šçŸ¥å‰ç«¯
        if account_id in active_queues:
            active_queues[account_id].put(status)

        return {"code": 200, "message": "Login status updated"}
    except Exception as e:
        print(f"ç™»å½•å®Œæˆå¤„ç†å¤±è´¥: {str(e)}")
        return {"code": 500, "message": f"Login completion failed: {str(e)}"}


if __name__ == "__main__":
    import uvicorn
    print("å¯åŠ¨å®Œæ•´AIåª’ä½“å¹³å°æœåŠ¡...")
    print("æœåŠ¡åœ°å€: http://localhost:9000")
    print("APIæ–‡æ¡£: http://localhost:9000/docs")
    print("æ”¯æŒçš„åŠŸèƒ½:")
    print("  - è§†é¢‘ç”Ÿæˆ")
    print("  - æ–‡æœ¬ä¼˜åŒ–")
    print("  - æ–‡ç« çˆ¬å–")
    print("  - ç¤¾äº¤å‘å¸ƒ")

    uvicorn.run(app, host="0.0.0.0", port=9000)